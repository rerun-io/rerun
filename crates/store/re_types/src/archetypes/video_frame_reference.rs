// DO NOT EDIT! This file was auto-generated by crates/build/re_types_builder/src/codegen/rust/api.rs
// Based on "crates/store/re_types/definitions/rerun/archetypes/video_frame_reference.fbs".

#![allow(unused_imports)]
#![allow(unused_parens)]
#![allow(clippy::clone_on_copy)]
#![allow(clippy::cloned_instead_of_copied)]
#![allow(clippy::map_flatten)]
#![allow(clippy::needless_question_mark)]
#![allow(clippy::new_without_default)]
#![allow(clippy::redundant_closure)]
#![allow(clippy::too_many_arguments)]
#![allow(clippy::too_many_lines)]

use ::re_types_core::try_serialize_field;
use ::re_types_core::SerializationResult;
use ::re_types_core::{ComponentBatch as _, SerializedComponentBatch};
use ::re_types_core::{ComponentDescriptor, ComponentName};
use ::re_types_core::{DeserializationError, DeserializationResult};

/// **Archetype**: References a single video frame.
///
/// Used to display individual video frames from a [`archetypes::AssetVideo`][crate::archetypes::AssetVideo].
/// To show an entire video, a video frame reference for each frame of the video should be logged.
///
/// See <https://rerun.io/docs/reference/video> for details of what is and isn't supported.
///
/// ## Examples
///
/// ### Video with automatically determined frames
/// ```ignore
/// use rerun::external::anyhow;
///
/// fn main() -> anyhow::Result<()> {
///     let args = _args;
///     let Some(path) = args.get(1) else {
///         // TODO(#7354): Only mp4 is supported for now.
///         anyhow::bail!("Usage: {} <path_to_video.[mp4]>", args[0]);
///     };
///
///     let rec =
///         rerun::RecordingStreamBuilder::new("rerun_example_asset_video_auto_frames").spawn()?;
///
///     // Log video asset which is referred to by frame references.
///     let video_asset = rerun::AssetVideo::from_file_path(path)?;
///     rec.log_static("video", &video_asset)?;
///
///     // Send automatically determined video frame timestamps.
///     let frame_timestamps_ns = video_asset.read_frame_timestamps_ns()?;
///     let video_timestamps_ns = frame_timestamps_ns
///         .iter()
///         .copied()
///         .map(rerun::components::VideoTimestamp::from_nanoseconds)
///         .collect::<Vec<_>>();
///     let time_column = rerun::TimeColumn::new_duration_nanos(
///         "video_time",
///         // Note timeline values don't have to be the same as the video timestamps.
///         frame_timestamps_ns,
///     );
///
///     rec.send_columns(
///         "video",
///         [time_column],
///         rerun::VideoFrameReference::update_fields()
///             .with_many_timestamp(video_timestamps_ns)
///             .columns_of_unit_batches()?,
///     )?;
///
///     Ok(())
/// }
/// ```
/// <center>
/// <picture>
///   <source media="(max-width: 480px)" srcset="https://static.rerun.io/video_manual_frames/320a44e1e06b8b3a3161ecbbeae3e04d1ccb9589/480w.png">
///   <source media="(max-width: 768px)" srcset="https://static.rerun.io/video_manual_frames/320a44e1e06b8b3a3161ecbbeae3e04d1ccb9589/768w.png">
///   <source media="(max-width: 1024px)" srcset="https://static.rerun.io/video_manual_frames/320a44e1e06b8b3a3161ecbbeae3e04d1ccb9589/1024w.png">
///   <source media="(max-width: 1200px)" srcset="https://static.rerun.io/video_manual_frames/320a44e1e06b8b3a3161ecbbeae3e04d1ccb9589/1200w.png">
///   <img src="https://static.rerun.io/video_manual_frames/320a44e1e06b8b3a3161ecbbeae3e04d1ccb9589/full.png" width="640">
/// </picture>
/// </center>
///
/// ### Demonstrates manual use of video frame references
/// ```ignore
/// use rerun::external::anyhow;
///
/// fn main() -> anyhow::Result<()> {
///     let args = _args;
///     let Some(path) = args.get(1) else {
///         // TODO(#7354): Only mp4 is supported for now.
///         anyhow::bail!("Usage: {} <path_to_video.[mp4]>", args[0]);
///     };
///
///     let rec =
///         rerun::RecordingStreamBuilder::new("rerun_example_asset_video_manual_frames").spawn()?;
///
///     // Log video asset which is referred to by frame references.
///     rec.log_static("video_asset", &rerun::AssetVideo::from_file_path(path)?)?;
///
///     // Create two entities, showing the same video frozen at different times.
///     rec.log(
///         "frame_1s",
///         &rerun::VideoFrameReference::new(rerun::components::VideoTimestamp::from_secs(1.0))
///             .with_video_reference("video_asset"),
///     )?;
///     rec.log(
///         "frame_2s",
///         &rerun::VideoFrameReference::new(rerun::components::VideoTimestamp::from_secs(2.0))
///             .with_video_reference("video_asset"),
///     )?;
///
///     // TODO(#5520): log blueprint once supported
///     Ok(())
/// }
/// ```
/// <center>
/// <picture>
///   <source media="(max-width: 480px)" srcset="https://static.rerun.io/video_manual_frames/9f41c00f84a98cc3f26875fba7c1d2fa2bad7151/480w.png">
///   <source media="(max-width: 768px)" srcset="https://static.rerun.io/video_manual_frames/9f41c00f84a98cc3f26875fba7c1d2fa2bad7151/768w.png">
///   <source media="(max-width: 1024px)" srcset="https://static.rerun.io/video_manual_frames/9f41c00f84a98cc3f26875fba7c1d2fa2bad7151/1024w.png">
///   <source media="(max-width: 1200px)" srcset="https://static.rerun.io/video_manual_frames/9f41c00f84a98cc3f26875fba7c1d2fa2bad7151/1200w.png">
///   <img src="https://static.rerun.io/video_manual_frames/9f41c00f84a98cc3f26875fba7c1d2fa2bad7151/full.png" width="640">
/// </picture>
/// </center>
#[derive(Clone, Debug, Default)]
pub struct VideoFrameReference {
    /// References the closest video frame to this timestamp.
    ///
    /// Note that this uses the closest video frame instead of the latest at this timestamp
    /// in order to be more forgiving of rounding errors for inprecise timestamp types.
    ///
    /// Timestamps are relative to the start of the video, i.e. a timestamp of 0 always corresponds to the first frame.
    /// This is oftentimes equivalent to presentation timestamps (known as PTS), but in the presence of B-frames
    /// (bidirectionally predicted frames) there may be an offset on the first presentation timestamp in the video.
    pub timestamp: Option<SerializedComponentBatch>,

    /// Optional reference to an entity with a [`archetypes::AssetVideo`][crate::archetypes::AssetVideo].
    ///
    /// If none is specified, the video is assumed to be at the same entity.
    /// Note that blueprint overrides on the referenced video will be ignored regardless,
    /// as this is always interpreted as a reference to the data store.
    ///
    /// For a series of video frame references, it is recommended to specify this path only once
    /// at the beginning of the series and then rely on latest-at query semantics to
    /// keep the video reference active.
    pub video_reference: Option<SerializedComponentBatch>,
}

impl VideoFrameReference {
    /// Returns the [`ComponentDescriptor`] for [`Self::timestamp`].
    #[inline]
    pub fn descriptor_timestamp() -> ComponentDescriptor {
        ComponentDescriptor {
            archetype_name: Some("rerun.archetypes.VideoFrameReference".into()),
            component_name: "rerun.components.VideoTimestamp".into(),
            archetype_field_name: Some("timestamp".into()),
        }
    }

    /// Returns the [`ComponentDescriptor`] for [`Self::video_reference`].
    #[inline]
    pub fn descriptor_video_reference() -> ComponentDescriptor {
        ComponentDescriptor {
            archetype_name: Some("rerun.archetypes.VideoFrameReference".into()),
            component_name: "rerun.components.EntityPath".into(),
            archetype_field_name: Some("video_reference".into()),
        }
    }

    /// Returns the [`ComponentDescriptor`] for the associated indicator component.
    #[inline]
    pub fn descriptor_indicator() -> ComponentDescriptor {
        ComponentDescriptor {
            archetype_name: Some("rerun.archetypes.VideoFrameReference".into()),
            component_name: "rerun.components.VideoFrameReferenceIndicator".into(),
            archetype_field_name: None,
        }
    }
}

static REQUIRED_COMPONENTS: once_cell::sync::Lazy<[ComponentDescriptor; 1usize]> =
    once_cell::sync::Lazy::new(|| [VideoFrameReference::descriptor_timestamp()]);

static RECOMMENDED_COMPONENTS: once_cell::sync::Lazy<[ComponentDescriptor; 1usize]> =
    once_cell::sync::Lazy::new(|| [VideoFrameReference::descriptor_indicator()]);

static OPTIONAL_COMPONENTS: once_cell::sync::Lazy<[ComponentDescriptor; 1usize]> =
    once_cell::sync::Lazy::new(|| [VideoFrameReference::descriptor_video_reference()]);

static ALL_COMPONENTS: once_cell::sync::Lazy<[ComponentDescriptor; 3usize]> =
    once_cell::sync::Lazy::new(|| {
        [
            VideoFrameReference::descriptor_timestamp(),
            VideoFrameReference::descriptor_indicator(),
            VideoFrameReference::descriptor_video_reference(),
        ]
    });

impl VideoFrameReference {
    /// The total number of components in the archetype: 1 required, 1 recommended, 1 optional
    pub const NUM_COMPONENTS: usize = 3usize;
}

/// Indicator component for the [`VideoFrameReference`] [`::re_types_core::Archetype`]
pub type VideoFrameReferenceIndicator =
    ::re_types_core::GenericIndicatorComponent<VideoFrameReference>;

impl ::re_types_core::Archetype for VideoFrameReference {
    type Indicator = VideoFrameReferenceIndicator;

    #[inline]
    fn name() -> ::re_types_core::ArchetypeName {
        "rerun.archetypes.VideoFrameReference".into()
    }

    #[inline]
    fn display_name() -> &'static str {
        "Video frame reference"
    }

    #[inline]
    fn indicator() -> SerializedComponentBatch {
        #[allow(clippy::unwrap_used)]
        VideoFrameReferenceIndicator::DEFAULT.serialized().unwrap()
    }

    #[inline]
    fn required_components() -> ::std::borrow::Cow<'static, [ComponentDescriptor]> {
        REQUIRED_COMPONENTS.as_slice().into()
    }

    #[inline]
    fn recommended_components() -> ::std::borrow::Cow<'static, [ComponentDescriptor]> {
        RECOMMENDED_COMPONENTS.as_slice().into()
    }

    #[inline]
    fn optional_components() -> ::std::borrow::Cow<'static, [ComponentDescriptor]> {
        OPTIONAL_COMPONENTS.as_slice().into()
    }

    #[inline]
    fn all_components() -> ::std::borrow::Cow<'static, [ComponentDescriptor]> {
        ALL_COMPONENTS.as_slice().into()
    }

    #[inline]
    fn from_arrow_components(
        arrow_data: impl IntoIterator<Item = (ComponentDescriptor, arrow::array::ArrayRef)>,
    ) -> DeserializationResult<Self> {
        re_tracing::profile_function!();
        use ::re_types_core::{Loggable as _, ResultExt as _};
        let arrays_by_descr: ::nohash_hasher::IntMap<_, _> = arrow_data.into_iter().collect();
        let timestamp = arrays_by_descr
            .get(&Self::descriptor_timestamp())
            .map(|array| {
                SerializedComponentBatch::new(array.clone(), Self::descriptor_timestamp())
            });
        let video_reference = arrays_by_descr
            .get(&Self::descriptor_video_reference())
            .map(|array| {
                SerializedComponentBatch::new(array.clone(), Self::descriptor_video_reference())
            });
        Ok(Self {
            timestamp,
            video_reference,
        })
    }
}

impl ::re_types_core::AsComponents for VideoFrameReference {
    #[inline]
    fn as_serialized_batches(&self) -> Vec<SerializedComponentBatch> {
        use ::re_types_core::Archetype as _;
        [
            Some(Self::indicator()),
            self.timestamp.clone(),
            self.video_reference.clone(),
        ]
        .into_iter()
        .flatten()
        .collect()
    }
}

impl ::re_types_core::ArchetypeReflectionMarker for VideoFrameReference {}

impl VideoFrameReference {
    /// Create a new `VideoFrameReference`.
    #[inline]
    pub fn new(timestamp: impl Into<crate::components::VideoTimestamp>) -> Self {
        Self {
            timestamp: try_serialize_field(Self::descriptor_timestamp(), [timestamp]),
            video_reference: None,
        }
    }

    /// Update only some specific fields of a `VideoFrameReference`.
    #[inline]
    pub fn update_fields() -> Self {
        Self::default()
    }

    /// Clear all the fields of a `VideoFrameReference`.
    #[inline]
    pub fn clear_fields() -> Self {
        use ::re_types_core::Loggable as _;
        Self {
            timestamp: Some(SerializedComponentBatch::new(
                crate::components::VideoTimestamp::arrow_empty(),
                Self::descriptor_timestamp(),
            )),
            video_reference: Some(SerializedComponentBatch::new(
                crate::components::EntityPath::arrow_empty(),
                Self::descriptor_video_reference(),
            )),
        }
    }

    /// Partitions the component data into multiple sub-batches.
    ///
    /// Specifically, this transforms the existing [`SerializedComponentBatch`]es data into [`SerializedComponentColumn`]s
    /// instead, via [`SerializedComponentBatch::partitioned`].
    ///
    /// This makes it possible to use `RecordingStream::send_columns` to send columnar data directly into Rerun.
    ///
    /// The specified `lengths` must sum to the total length of the component batch.
    ///
    /// [`SerializedComponentColumn`]: [::re_types_core::SerializedComponentColumn]
    #[inline]
    pub fn columns<I>(
        self,
        _lengths: I,
    ) -> SerializationResult<impl Iterator<Item = ::re_types_core::SerializedComponentColumn>>
    where
        I: IntoIterator<Item = usize> + Clone,
    {
        let columns = [
            self.timestamp
                .map(|timestamp| timestamp.partitioned(_lengths.clone()))
                .transpose()?,
            self.video_reference
                .map(|video_reference| video_reference.partitioned(_lengths.clone()))
                .transpose()?,
        ];
        Ok(columns
            .into_iter()
            .flatten()
            .chain([::re_types_core::indicator_column::<Self>(
                _lengths.into_iter().count(),
            )?]))
    }

    /// Helper to partition the component data into unit-length sub-batches.
    ///
    /// This is semantically similar to calling [`Self::columns`] with `std::iter::take(1).repeat(n)`,
    /// where `n` is automatically guessed.
    #[inline]
    pub fn columns_of_unit_batches(
        self,
    ) -> SerializationResult<impl Iterator<Item = ::re_types_core::SerializedComponentColumn>> {
        let len_timestamp = self.timestamp.as_ref().map(|b| b.array.len());
        let len_video_reference = self.video_reference.as_ref().map(|b| b.array.len());
        let len = None.or(len_timestamp).or(len_video_reference).unwrap_or(0);
        self.columns(std::iter::repeat(1).take(len))
    }

    /// References the closest video frame to this timestamp.
    ///
    /// Note that this uses the closest video frame instead of the latest at this timestamp
    /// in order to be more forgiving of rounding errors for inprecise timestamp types.
    ///
    /// Timestamps are relative to the start of the video, i.e. a timestamp of 0 always corresponds to the first frame.
    /// This is oftentimes equivalent to presentation timestamps (known as PTS), but in the presence of B-frames
    /// (bidirectionally predicted frames) there may be an offset on the first presentation timestamp in the video.
    #[inline]
    pub fn with_timestamp(
        mut self,
        timestamp: impl Into<crate::components::VideoTimestamp>,
    ) -> Self {
        self.timestamp = try_serialize_field(Self::descriptor_timestamp(), [timestamp]);
        self
    }

    /// This method makes it possible to pack multiple [`crate::components::VideoTimestamp`] in a single component batch.
    ///
    /// This only makes sense when used in conjunction with [`Self::columns`]. [`Self::with_timestamp`] should
    /// be used when logging a single row's worth of data.
    #[inline]
    pub fn with_many_timestamp(
        mut self,
        timestamp: impl IntoIterator<Item = impl Into<crate::components::VideoTimestamp>>,
    ) -> Self {
        self.timestamp = try_serialize_field(Self::descriptor_timestamp(), timestamp);
        self
    }

    /// Optional reference to an entity with a [`archetypes::AssetVideo`][crate::archetypes::AssetVideo].
    ///
    /// If none is specified, the video is assumed to be at the same entity.
    /// Note that blueprint overrides on the referenced video will be ignored regardless,
    /// as this is always interpreted as a reference to the data store.
    ///
    /// For a series of video frame references, it is recommended to specify this path only once
    /// at the beginning of the series and then rely on latest-at query semantics to
    /// keep the video reference active.
    #[inline]
    pub fn with_video_reference(
        mut self,
        video_reference: impl Into<crate::components::EntityPath>,
    ) -> Self {
        self.video_reference =
            try_serialize_field(Self::descriptor_video_reference(), [video_reference]);
        self
    }

    /// This method makes it possible to pack multiple [`crate::components::EntityPath`] in a single component batch.
    ///
    /// This only makes sense when used in conjunction with [`Self::columns`]. [`Self::with_video_reference`] should
    /// be used when logging a single row's worth of data.
    #[inline]
    pub fn with_many_video_reference(
        mut self,
        video_reference: impl IntoIterator<Item = impl Into<crate::components::EntityPath>>,
    ) -> Self {
        self.video_reference =
            try_serialize_field(Self::descriptor_video_reference(), video_reference);
        self
    }
}

impl ::re_byte_size::SizeBytes for VideoFrameReference {
    #[inline]
    fn heap_size_bytes(&self) -> u64 {
        self.timestamp.heap_size_bytes() + self.video_reference.heap_size_bytes()
    }
}
