// DO NOT EDIT! This file was auto-generated by crates/build/re_types_builder/src/codegen/rust/api.rs
// Based on "crates/store/re_sdk_types/definitions/rerun/archetypes/video_stream.fbs".

#![allow(unused_braces)]
#![allow(unused_imports)]
#![allow(unused_parens)]
#![allow(clippy::allow_attributes)]
#![allow(clippy::clone_on_copy)]
#![allow(clippy::cloned_instead_of_copied)]
#![allow(clippy::map_flatten)]
#![allow(clippy::needless_question_mark)]
#![allow(clippy::new_without_default)]
#![allow(clippy::redundant_closure)]
#![allow(clippy::too_many_arguments)]
#![allow(clippy::too_many_lines)]
#![allow(clippy::wildcard_imports)]

use ::re_types_core::SerializationResult;
use ::re_types_core::try_serialize_field;
use ::re_types_core::{ComponentBatch as _, SerializedComponentBatch};
use ::re_types_core::{ComponentDescriptor, ComponentType};
use ::re_types_core::{DeserializationError, DeserializationResult};

/// **Archetype**: Video stream consisting of raw video chunks.
///
/// For logging video containers like mp4, refer to [`archetypes::AssetVideo`][crate::archetypes::AssetVideo] and [`archetypes::VideoFrameReference`][crate::archetypes::VideoFrameReference].
/// To learn more about video support in Rerun, check the [video reference](https://rerun.io/docs/reference/video).
///
/// All components except `sample` are typically logged statically once per entity.
/// `sample` is then logged repeatedly for each frame on the timeline.
///
/// TODO(#10422): [`archetypes::VideoFrameReference`][crate::archetypes::VideoFrameReference] does not yet work with [`archetypes::VideoStream`][crate::archetypes::VideoStream].
///
/// ⚠️ **This type is _unstable_ and may change significantly in a way that the data won't be backwards compatible.**
#[derive(Clone, Debug, Default)]
pub struct VideoStream {
    /// The codec used to encode the video chunks.
    ///
    /// This property is expected to be constant over time and is ideally logged statically once per stream.
    pub codec: Option<SerializedComponentBatch>,

    /// Video sample data (also known as "video chunk").
    ///
    /// The current timestamp is used as presentation timestamp (PTS) for all data in this sample.
    /// There is currently no way to log differing decoding timestamps, meaning
    /// that there is no support for B-frames.
    /// See <https://github.com/rerun-io/rerun/issues/10090> for more details.
    ///
    /// Rerun chunks containing frames (i.e. bundles of sample data) may arrive out of order,
    /// but may cause the video playback in the Viewer to reset.
    /// It is recommended to have all chunks for a video stream to be ordered temporally order.
    ///
    /// Logging separate videos on the same entity is allowed iff they share the exact same
    /// codec parameters & resolution.
    ///
    /// The samples are expected to be encoded using the `codec` field.
    /// Each video sample must contain enough data for exactly one video frame
    /// (this restriction may be relaxed in the future for some codecs).
    ///
    /// Unless your stream consists entirely of key-frames (in which case you should consider [`archetypes::EncodedImage`][crate::archetypes::EncodedImage])
    /// never log this component as static data as this means that you loose all information of
    /// previous samples which may be required to decode an image.
    ///
    /// See [`components::VideoCodec`][crate::components::VideoCodec] for codec specific requirements.
    pub sample: Option<SerializedComponentBatch>,

    /// Opacity of the video stream, useful for layering several media.
    ///
    /// Defaults to 1.0 (fully opaque).
    pub opacity: Option<SerializedComponentBatch>,

    /// An optional floating point value that specifies the 2D drawing order.
    ///
    /// Objects with higher values are drawn on top of those with lower values.
    /// Defaults to `-15.0`.
    pub draw_order: Option<SerializedComponentBatch>,
}

impl VideoStream {
    /// Returns the [`ComponentDescriptor`] for [`Self::codec`].
    ///
    /// The corresponding component is [`crate::components::VideoCodec`].
    #[inline]
    pub fn descriptor_codec() -> ComponentDescriptor {
        ComponentDescriptor {
            archetype: Some("rerun.archetypes.VideoStream".into()),
            component: "VideoStream:codec".into(),
            component_type: Some("rerun.components.VideoCodec".into()),
        }
    }

    /// Returns the [`ComponentDescriptor`] for [`Self::sample`].
    ///
    /// The corresponding component is [`crate::components::VideoSample`].
    #[inline]
    pub fn descriptor_sample() -> ComponentDescriptor {
        ComponentDescriptor {
            archetype: Some("rerun.archetypes.VideoStream".into()),
            component: "VideoStream:sample".into(),
            component_type: Some("rerun.components.VideoSample".into()),
        }
    }

    /// Returns the [`ComponentDescriptor`] for [`Self::opacity`].
    ///
    /// The corresponding component is [`crate::components::Opacity`].
    #[inline]
    pub fn descriptor_opacity() -> ComponentDescriptor {
        ComponentDescriptor {
            archetype: Some("rerun.archetypes.VideoStream".into()),
            component: "VideoStream:opacity".into(),
            component_type: Some("rerun.components.Opacity".into()),
        }
    }

    /// Returns the [`ComponentDescriptor`] for [`Self::draw_order`].
    ///
    /// The corresponding component is [`crate::components::DrawOrder`].
    #[inline]
    pub fn descriptor_draw_order() -> ComponentDescriptor {
        ComponentDescriptor {
            archetype: Some("rerun.archetypes.VideoStream".into()),
            component: "VideoStream:draw_order".into(),
            component_type: Some("rerun.components.DrawOrder".into()),
        }
    }
}

static REQUIRED_COMPONENTS: std::sync::LazyLock<[ComponentDescriptor; 1usize]> =
    std::sync::LazyLock::new(|| [VideoStream::descriptor_codec()]);

static RECOMMENDED_COMPONENTS: std::sync::LazyLock<[ComponentDescriptor; 1usize]> =
    std::sync::LazyLock::new(|| [VideoStream::descriptor_sample()]);

static OPTIONAL_COMPONENTS: std::sync::LazyLock<[ComponentDescriptor; 2usize]> =
    std::sync::LazyLock::new(|| {
        [
            VideoStream::descriptor_opacity(),
            VideoStream::descriptor_draw_order(),
        ]
    });

static ALL_COMPONENTS: std::sync::LazyLock<[ComponentDescriptor; 4usize]> =
    std::sync::LazyLock::new(|| {
        [
            VideoStream::descriptor_codec(),
            VideoStream::descriptor_sample(),
            VideoStream::descriptor_opacity(),
            VideoStream::descriptor_draw_order(),
        ]
    });

impl VideoStream {
    /// The total number of components in the archetype: 1 required, 1 recommended, 2 optional
    pub const NUM_COMPONENTS: usize = 4usize;
}

impl ::re_types_core::Archetype for VideoStream {
    #[inline]
    fn name() -> ::re_types_core::ArchetypeName {
        "rerun.archetypes.VideoStream".into()
    }

    #[inline]
    fn display_name() -> &'static str {
        "Video stream"
    }

    #[inline]
    fn required_components() -> ::std::borrow::Cow<'static, [ComponentDescriptor]> {
        REQUIRED_COMPONENTS.as_slice().into()
    }

    #[inline]
    fn recommended_components() -> ::std::borrow::Cow<'static, [ComponentDescriptor]> {
        RECOMMENDED_COMPONENTS.as_slice().into()
    }

    #[inline]
    fn optional_components() -> ::std::borrow::Cow<'static, [ComponentDescriptor]> {
        OPTIONAL_COMPONENTS.as_slice().into()
    }

    #[inline]
    fn all_components() -> ::std::borrow::Cow<'static, [ComponentDescriptor]> {
        ALL_COMPONENTS.as_slice().into()
    }

    #[inline]
    fn from_arrow_components(
        arrow_data: impl IntoIterator<Item = (ComponentDescriptor, arrow::array::ArrayRef)>,
    ) -> DeserializationResult<Self> {
        re_tracing::profile_function!();
        use ::re_types_core::{Loggable as _, ResultExt as _};
        let arrays_by_descr: ::nohash_hasher::IntMap<_, _> = arrow_data.into_iter().collect();
        let codec = arrays_by_descr
            .get(&Self::descriptor_codec())
            .map(|array| SerializedComponentBatch::new(array.clone(), Self::descriptor_codec()));
        let sample = arrays_by_descr
            .get(&Self::descriptor_sample())
            .map(|array| SerializedComponentBatch::new(array.clone(), Self::descriptor_sample()));
        let opacity = arrays_by_descr
            .get(&Self::descriptor_opacity())
            .map(|array| SerializedComponentBatch::new(array.clone(), Self::descriptor_opacity()));
        let draw_order = arrays_by_descr
            .get(&Self::descriptor_draw_order())
            .map(|array| {
                SerializedComponentBatch::new(array.clone(), Self::descriptor_draw_order())
            });
        Ok(Self {
            codec,
            sample,
            opacity,
            draw_order,
        })
    }
}

impl ::re_types_core::AsComponents for VideoStream {
    #[inline]
    fn as_serialized_batches(&self) -> Vec<SerializedComponentBatch> {
        use ::re_types_core::Archetype as _;
        [
            self.codec.clone(),
            self.sample.clone(),
            self.opacity.clone(),
            self.draw_order.clone(),
        ]
        .into_iter()
        .flatten()
        .collect()
    }
}

impl ::re_types_core::ArchetypeReflectionMarker for VideoStream {}

impl crate::VisualizableArchetype for VideoStream {
    #[inline]
    fn visualizer(&self) -> crate::Visualizer {
        crate::Visualizer::new("VideoStream").with_overrides(self)
    }
}

impl VideoStream {
    /// Create a new `VideoStream`.
    #[inline]
    pub fn new(codec: impl Into<crate::components::VideoCodec>) -> Self {
        Self {
            codec: try_serialize_field(Self::descriptor_codec(), [codec]),
            sample: None,
            opacity: None,
            draw_order: None,
        }
    }

    /// Update only some specific fields of a `VideoStream`.
    #[inline]
    pub fn update_fields() -> Self {
        Self::default()
    }

    /// Clear all the fields of a `VideoStream`.
    #[inline]
    pub fn clear_fields() -> Self {
        use ::re_types_core::Loggable as _;
        Self {
            codec: Some(SerializedComponentBatch::new(
                crate::components::VideoCodec::arrow_empty(),
                Self::descriptor_codec(),
            )),
            sample: Some(SerializedComponentBatch::new(
                crate::components::VideoSample::arrow_empty(),
                Self::descriptor_sample(),
            )),
            opacity: Some(SerializedComponentBatch::new(
                crate::components::Opacity::arrow_empty(),
                Self::descriptor_opacity(),
            )),
            draw_order: Some(SerializedComponentBatch::new(
                crate::components::DrawOrder::arrow_empty(),
                Self::descriptor_draw_order(),
            )),
        }
    }

    /// Partitions the component data into multiple sub-batches.
    ///
    /// Specifically, this transforms the existing [`SerializedComponentBatch`]es data into [`SerializedComponentColumn`]s
    /// instead, via [`SerializedComponentBatch::partitioned`].
    ///
    /// This makes it possible to use `RecordingStream::send_columns` to send columnar data directly into Rerun.
    ///
    /// The specified `lengths` must sum to the total length of the component batch.
    ///
    /// [`SerializedComponentColumn`]: [::re_types_core::SerializedComponentColumn]
    #[inline]
    pub fn columns<I>(
        self,
        _lengths: I,
    ) -> SerializationResult<impl Iterator<Item = ::re_types_core::SerializedComponentColumn>>
    where
        I: IntoIterator<Item = usize> + Clone,
    {
        let columns = [
            self.codec
                .map(|codec| codec.partitioned(_lengths.clone()))
                .transpose()?,
            self.sample
                .map(|sample| sample.partitioned(_lengths.clone()))
                .transpose()?,
            self.opacity
                .map(|opacity| opacity.partitioned(_lengths.clone()))
                .transpose()?,
            self.draw_order
                .map(|draw_order| draw_order.partitioned(_lengths.clone()))
                .transpose()?,
        ];
        Ok(columns.into_iter().flatten())
    }

    /// Helper to partition the component data into unit-length sub-batches.
    ///
    /// This is semantically similar to calling [`Self::columns`] with `std::iter::take(1).repeat(n)`,
    /// where `n` is automatically guessed.
    #[inline]
    pub fn columns_of_unit_batches(
        self,
    ) -> SerializationResult<impl Iterator<Item = ::re_types_core::SerializedComponentColumn>> {
        let len_codec = self.codec.as_ref().map(|b| b.array.len());
        let len_sample = self.sample.as_ref().map(|b| b.array.len());
        let len_opacity = self.opacity.as_ref().map(|b| b.array.len());
        let len_draw_order = self.draw_order.as_ref().map(|b| b.array.len());
        let len = None
            .or(len_codec)
            .or(len_sample)
            .or(len_opacity)
            .or(len_draw_order)
            .unwrap_or(0);
        self.columns(std::iter::repeat_n(1, len))
    }

    /// The codec used to encode the video chunks.
    ///
    /// This property is expected to be constant over time and is ideally logged statically once per stream.
    #[inline]
    pub fn with_codec(mut self, codec: impl Into<crate::components::VideoCodec>) -> Self {
        self.codec = try_serialize_field(Self::descriptor_codec(), [codec]);
        self
    }

    /// This method makes it possible to pack multiple [`crate::components::VideoCodec`] in a single component batch.
    ///
    /// This only makes sense when used in conjunction with [`Self::columns`]. [`Self::with_codec`] should
    /// be used when logging a single row's worth of data.
    #[inline]
    pub fn with_many_codec(
        mut self,
        codec: impl IntoIterator<Item = impl Into<crate::components::VideoCodec>>,
    ) -> Self {
        self.codec = try_serialize_field(Self::descriptor_codec(), codec);
        self
    }

    /// Video sample data (also known as "video chunk").
    ///
    /// The current timestamp is used as presentation timestamp (PTS) for all data in this sample.
    /// There is currently no way to log differing decoding timestamps, meaning
    /// that there is no support for B-frames.
    /// See <https://github.com/rerun-io/rerun/issues/10090> for more details.
    ///
    /// Rerun chunks containing frames (i.e. bundles of sample data) may arrive out of order,
    /// but may cause the video playback in the Viewer to reset.
    /// It is recommended to have all chunks for a video stream to be ordered temporally order.
    ///
    /// Logging separate videos on the same entity is allowed iff they share the exact same
    /// codec parameters & resolution.
    ///
    /// The samples are expected to be encoded using the `codec` field.
    /// Each video sample must contain enough data for exactly one video frame
    /// (this restriction may be relaxed in the future for some codecs).
    ///
    /// Unless your stream consists entirely of key-frames (in which case you should consider [`archetypes::EncodedImage`][crate::archetypes::EncodedImage])
    /// never log this component as static data as this means that you loose all information of
    /// previous samples which may be required to decode an image.
    ///
    /// See [`components::VideoCodec`][crate::components::VideoCodec] for codec specific requirements.
    #[inline]
    pub fn with_sample(mut self, sample: impl Into<crate::components::VideoSample>) -> Self {
        self.sample = try_serialize_field(Self::descriptor_sample(), [sample]);
        self
    }

    /// This method makes it possible to pack multiple [`crate::components::VideoSample`] in a single component batch.
    ///
    /// This only makes sense when used in conjunction with [`Self::columns`]. [`Self::with_sample`] should
    /// be used when logging a single row's worth of data.
    #[inline]
    pub fn with_many_sample(
        mut self,
        sample: impl IntoIterator<Item = impl Into<crate::components::VideoSample>>,
    ) -> Self {
        self.sample = try_serialize_field(Self::descriptor_sample(), sample);
        self
    }

    /// Opacity of the video stream, useful for layering several media.
    ///
    /// Defaults to 1.0 (fully opaque).
    #[inline]
    pub fn with_opacity(mut self, opacity: impl Into<crate::components::Opacity>) -> Self {
        self.opacity = try_serialize_field(Self::descriptor_opacity(), [opacity]);
        self
    }

    /// This method makes it possible to pack multiple [`crate::components::Opacity`] in a single component batch.
    ///
    /// This only makes sense when used in conjunction with [`Self::columns`]. [`Self::with_opacity`] should
    /// be used when logging a single row's worth of data.
    #[inline]
    pub fn with_many_opacity(
        mut self,
        opacity: impl IntoIterator<Item = impl Into<crate::components::Opacity>>,
    ) -> Self {
        self.opacity = try_serialize_field(Self::descriptor_opacity(), opacity);
        self
    }

    /// An optional floating point value that specifies the 2D drawing order.
    ///
    /// Objects with higher values are drawn on top of those with lower values.
    /// Defaults to `-15.0`.
    #[inline]
    pub fn with_draw_order(mut self, draw_order: impl Into<crate::components::DrawOrder>) -> Self {
        self.draw_order = try_serialize_field(Self::descriptor_draw_order(), [draw_order]);
        self
    }

    /// This method makes it possible to pack multiple [`crate::components::DrawOrder`] in a single component batch.
    ///
    /// This only makes sense when used in conjunction with [`Self::columns`]. [`Self::with_draw_order`] should
    /// be used when logging a single row's worth of data.
    #[inline]
    pub fn with_many_draw_order(
        mut self,
        draw_order: impl IntoIterator<Item = impl Into<crate::components::DrawOrder>>,
    ) -> Self {
        self.draw_order = try_serialize_field(Self::descriptor_draw_order(), draw_order);
        self
    }
}

impl ::re_byte_size::SizeBytes for VideoStream {
    #[inline]
    fn heap_size_bytes(&self) -> u64 {
        self.codec.heap_size_bytes()
            + self.sample.heap_size_bytes()
            + self.opacity.heap_size_bytes()
            + self.draw_order.heap_size_bytes()
    }
}
