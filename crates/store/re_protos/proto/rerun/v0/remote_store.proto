syntax = "proto3";

package rerun.remote_store.v0;

import "rerun/v0/common.proto";

service StorageNode {
    // data API calls
    rpc Query(QueryRequest) returns (stream DataframePart) {}
    rpc FetchRecording(FetchRecordingRequest) returns (stream rerun.common.v0.RerunChunk) {}

    // metadata API calls
    rpc QueryCatalog(QueryCatalogRequest) returns (stream DataframePart) {}
    rpc UpdateCatalog(UpdateCatalogRequest) returns (UpdateCatalogResponse) {}
    // TODO(zehiko) support registering more than one recording at a time
    rpc RegisterRecording(RegisterRecordingRequest) returns (DataframePart) {}
}

// ---------------- Common response message ------------------

// DataframePart is arrow IPC encoded RecordBatch
message DataframePart {
    // encoder version used to encode the data
    rerun.common.v0.EncoderVersion encoder_version = 1;

    // Data payload is Arrow IPC encoded RecordBatch
    bytes payload = 1000;
}

// ---------------- RegisterRecording ------------------

message RegisterRecordingRequest {
    // human readable description of the recording
    string description = 1;
    // recording storage url (e.g. s3://bucket/file or file:///path/to/file)
    string storage_url = 2;
    // type of recording
    RecordingType typ = 3;
    // (optional) any additional metadata that should be associated with the recording
    // You can associate any arbtrirary number of columns with a specific recording
    DataframePart metadata = 4;
}

// ---------------- UpdateCatalog  -----------------

message UpdateCatalogRequest {
    DataframePart metadata = 2;
}

message UpdateCatalogResponse {}

// ---------------- Query -----------------

message QueryRequest {
    // unique identifier of the recording
    rerun.common.v0.RecordingId recording_id = 1;
    // query to execute
    rerun.common.v0.Query query = 3;
}

// ----------------- QueryCatalog -----------------

message QueryCatalogRequest {
    // Column projection - define which columns should be returned.
    // Providing it is optional, if not provided, all columns should be returned
    ColumnProjection column_projection = 1;
    // Filter specific recordings that match the criteria (selection)
    CatalogFilter filter = 2;
}

message ColumnProjection {
    repeated string columns = 1;
}

message CatalogFilter {
    // Filtering is very simple right now, we can only select
    // recordings by their ids.
    repeated rerun.common.v0.RecordingId recording_ids = 1;
}

message QueryCatalogResponse {
    rerun.common.v0.EncoderVersion encoder_version = 1;
    // raw bytes are TransportChunks (i.e. RecordBatches) encoded with the relevant codec
    bytes payload = 2;
}

enum RecordingType {
    RRD = 0;
}

// ----------------- FetchRecording -----------------

message FetchRecordingRequest {
    rerun.common.v0.RecordingId recording_id = 1;
}

// TODO(jleibs): Eventually this becomes either query-mediated in some way, but for now
// it's useful to be able to just get back the whole RRD somehow.
message FetchRecordingResponse {
    // TODO(zehiko) we need to expand this to become something like 'encoder options'
    // as we will need to specify additional options like compression, including schema
    // in payload, etc.
    rerun.common.v0.EncoderVersion encoder_version = 1;
    // payload is raw bytes that the relevant codec can interpret
    bytes payload = 2;
}

// ----------------- Error handling -----------------

// Application level error - used as `details` in the `google.rpc.Status` message
message RemoteStoreError {
    // error code
    ErrorCode code = 1;
    // unique identifier associated with the request (e.g. recording id, recording storage url)
    string id = 2;
    // human readable details about the error
    string message = 3;
}

// Error codes for application level errors
enum ErrorCode {
    // unused
    _UNUSED = 0;

    // object store access error
    OBJECT_STORE_ERROR = 1;

    // metadata database access error
    METADATA_DB_ERROR = 2;

    // Encoding / decoding error
    CODEC_ERROR = 3;
}
