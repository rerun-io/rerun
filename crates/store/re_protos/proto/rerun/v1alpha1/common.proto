syntax = "proto3";

package rerun.common.v1alpha1;

// TODO(cmc): aren't most of the definitions in here dead code?

// supported encoder versions for encoding data
// See `RerunData` and `RerunChunkData` for its usage
enum EncoderVersion {
  ENCODER_VERSION_UNSPECIFIED = 0;
  ENCODER_VERSION_V0 = 1;
}

// RerunChunk is arrow IPC encoded RecordBatch that has
// rerun-specific semantic constraints and can be directly
// converted to a Rerun Chunk (`re_chunk::Chunk`)
message RerunChunk {
  // encoder version used to encode the data
  EncoderVersion encoder_version = 1;

  // Data payload is Arrow IPC encoded RecordBatch
  // TODO(zehiko) make this optional (#9285)
  bytes payload = 2;
}

// unique recording identifier. At this point in time it is the same id as the ChunkStore's StoreId
message RecordingId {
  string id = 1;
}

// uniquely identifies a table
message TableId {
  string id = 1;
}

// A recording can have multiple timelines, each is identified by a name, for example `log_tick`, `log_time`, etc.
message Timeline {
  string name = 1;
}

// A time range between start and end time points. Each 64 bit number can represent different time point data
// depending on the timeline it is associated with. Time range is inclusive for both start and end time points.
message TimeRange {
  int64 start = 1;
  int64 end = 2;
}

// arrow IPC serialized schema
message Schema {
  optional bytes arrow_schema = 1;
}

// TODO(cmc): can we kill this?
message Query {
  // The subset of the database that the query will run on: a set of EntityPath(s) and their
  // associated Component(s)
  ViewContents view_contents = 1;

  // Whether the view_contents should ignore semantically empty columns
  // A semantically empty column is a column that either contains no data at all, or where all
  // values are either nulls or empty arrays ([]).
  bool include_semantically_empty_columns = 2;

  // Whether the view_contents should ignore columns corresponding to indicator components
  // Indicator components are marker components, generally automatically inserted by Rerun, that
  // helps keep track of the original context in which a piece of data was logged/sent.
  bool include_indicator_columns = 3;

  // Whether the view_contents should ignore columns corresponding to Clear-related components
  bool include_tombstone_columns = 4;

  // The index used to filter out _rows_ from the view contents.
  // Only rows where at least 1 column contains non-null data at that index will be kept in the
  // final dataset. If left unspecified, the results will only contain static data.
  IndexColumnSelector filtered_index = 5;

  // The range of index values used to filter out _rows_ from the view contents
  // Only rows where at least 1 of the view-contents contains non-null data within that range will be kept in
  // the final dataset.
  // This has no effect if filtered_index isn't set.
  // This has no effect if using_index_values is set.
  IndexRange filtered_index_range = 6;

  // The specific index values used to filter out _rows_ from the view contents.
  // Only rows where at least 1 column contains non-null data at these specific values will be kept
  // in the final dataset.
  // This has no effect if filtered_index isn't set.
  // This has no effect if using_index_values is set.
  IndexValues filtered_index_values = 7;

  // The specific index values used to sample _rows_ from the view contents.
  // The final dataset will contain one row per sampled index value, regardless of whether data
  // existed for that index value in the view contents.
  // The semantics of the query are consistent with all other settings: the results will be
  // sorted on the filtered_index, and only contain unique index values.
  //
  // This has no effect if filtered_index isn't set.
  // If set, this overrides both filtered_index_range and filtered_index_values.
  IndexValues using_index_values = 8;

  // The component column used to filter out _rows_ from the view contents.
  // Only rows where this column contains non-null data be kept in the final dataset.
  ComponentColumnSelector filtered_is_not_null = 9;

  // The specific _columns_ to sample from the final view contents.
  // The order of the samples will be respected in the final result.
  //
  // If unspecified, it means - everything.
  ColumnSelection column_selection = 10;

  // Specifies how null values should be filled in the returned dataframe.
  SparseFillStrategy sparse_fill_strategy = 11;

  reserved 12;
  reserved "include_properties_entity";
}

message ColumnSelection {
  repeated ColumnSelector columns = 1;
}

message ColumnSelector {
  oneof selector_type {
    ComponentColumnSelector component_column = 2;
    TimeColumnSelector time_column = 3;
  }
}

message IndexColumnSelector {
  // TODO(zehiko) we need to add support for other types of index selectors
  Timeline timeline = 1;
}

message IndexRange {
  // TODO(zehiko) support for other ranges for other index selectors
  TimeRange time_range = 1;
}

message IndexValues {
  // TODO(zehiko) we need to add support for other types of index selectors
  repeated TimeInt time_points = 1;
}

message SampledIndexValues {
  repeated TimeInt sample_points = 1;
}

// A 64-bit number describing either nanoseconds, sequence numbers or fully static data.
message TimeInt {
  int64 time = 1;
}

message ViewContents {
  repeated ViewContentsPart contents = 1;
}

message ViewContentsPart {
  EntityPath path = 1;
  ComponentsSet components = 2;
}

message ComponentsSet {
  repeated Component components = 1;
}

// The unique identifier of an entity, e.g. `camera/3/points`
// See <https://www.rerun.io/docs/concepts/entity-path> for more on entity paths.
message EntityPath {
  string path = 1;
}

// Component describes semantic data that can be used by any number of  rerun's archetypes.
message Component {
  // component name needs to be a string as user can define their own component
  string name = 1;
}

// Used to telect a time column.
message TimeColumnSelector {
  Timeline timeline = 1;
}

// Used to select a component based on its EntityPath and Component name.
message ComponentColumnSelector {
  EntityPath entity_path = 1;
  Component component = 2;
}

// Specifies how null values should be filled in the returned dataframe.
enum SparseFillStrategy {
  SPARSE_FILL_STRATEGY_UNSPECIFIED = 0;
  SPARSE_FILL_STRATEGY_NONE = 1;
  SPARSE_FILL_STRATEGY_LATEST_AT_GLOBAL = 2;
}

message ApplicationId {
  string id = 1;
}

enum StoreKind {
  STORE_KIND_UNSPECIFIED = 0;
  STORE_KIND_RECORDING = 1;
  STORE_KIND_BLUEPRINT = 2;
}

message StoreId {
  StoreKind kind = 1;
  string id = 2;
}

message Tuid {
  // Approximate nanoseconds since epoch.
  optional fixed64 time_ns = 1;

  // Initialized to something random on each thread, then incremented for each
  // new `Tuid` being allocated.
  optional fixed64 inc = 2;
}

message EntryId {
  Tuid id = 1;
}

// Entry point for all ManifestRegistryService APIs
message DatasetHandle {
  // Unique entry identifier (for debug purposes)
  EntryId entry_id = 1;

  // Path to Dataset backing storage (e.g. s3://bucket/file or file:///path/to/file)
  optional string dataset_url = 2;
}

// DataframePart is arrow IPC encoded RecordBatch
message DataframePart {
  // encoder version used to encode the data
  EncoderVersion encoder_version = 1;

  // Data payload is Arrow IPC encoded RecordBatch
  optional bytes payload = 2;
}

// Generic parameters that will influence the behavior of the Lance scanner.
//
// TODO(zehiko, cmc): This should be available for every endpoint that queries data in
// one way or another.
message ScanParameters {
  // List of columns to project. If empty, all columns will be projected.
  repeated string columns = 1;

  IfMissingBehavior on_missing_columns = 2;

  // An arbitrary filter expression that will be passed to the Lance scanner as-is.
  //
  // ```text
  // scanner.filter(filter)
  // ```
  optional string filter = 3;

  // An arbitrary offset that will be passed to the Lance scanner as-is.
  //
  // ```text
  // scanner.limit(_, limit_offset)
  // ```
  optional int64 limit_offset = 4;

  // An arbitrary limit that will be passed to the Lance scanner as-is.
  //
  // ```text
  // scanner.limit(limit_len, _)
  // ```
  optional int64 limit_len = 5;

  // An arbitrary order clause that will be passed to the Lance scanner as-is.
  //
  // ```text
  // scanner.order_by(â€¦)
  // ```
  ScanParametersOrderClause order_by = 6;

  // If set, the output of `scanner.explain_plan` will be dumped to the server's log.
  bool explain_plan = 7;

  // If set, the final `scanner.filter` will be dumped to the server's log.
  bool explain_filter = 8;
}

enum IfMissingBehavior {
  IF_MISSING_BEHAVIOR_UNSPECIFIED = 0;
  IF_MISSING_BEHAVIOR_SKIP = 1;
  IF_MISSING_BEHAVIOR_ERROR = 2;
}

// Specify how the relevant creation call behaves
// in case of previously created (duplicate) items
enum IfDuplicateBehavior {
  IF_DUPLICATE_BEHAVIOR_UNSPECIFIED = 0;

  // Overwrite the existing item
  IF_DUPLICATE_BEHAVIOR_OVERWRITE = 1;

  // Skip if the item already exists
  IF_DUPLICATE_BEHAVIOR_SKIP = 2;

  // Return an error if the item already exists
  IF_DUPLICATE_BEHAVIOR_ERROR = 3;
}

message ScanParametersOrderClause {
  bool descending = 1;
  bool nulls_last = 2;
  optional string column_name = 3;
}

// Unique identifier for a partition. Can be user defined
// which means it can be of any type. For simplicity we start
// with a string, but we will probably revisit this.
message PartitionId {
  optional string id = 1;
}

message ComponentDescriptor {
  // Optional name of the `Archetype` associated with this data.
  optional string archetype_name = 1;

  // Optional name of the field within `Archetype` associated with this data.
  optional string archetype_field_name = 2;

  // Semantic name associated with this data.
  optional string component_name = 3;
}

// Unique identifier of a task submitted in the redap
// tasks subsystem
message TaskId {
  string id = 1;
}
