syntax = "proto3";

package rerun.common.v1alpha1;

// The type of compression used on the payload.
enum Compression {
  COMPRESSION_UNSPECIFIED = 0;

  // No compression.
  COMPRESSION_NONE = 1;

  // LZ4 block compression.
  COMPRESSION_LZ4 = 2;
}

// supported encoder versions for encoding data
// See `RerunData` and `RerunChunkData` for its usage
enum EncoderVersion {
  ENCODER_VERSION_UNSPECIFIED = 0;
  ENCODER_VERSION_V0 = 1;
}

// RerunChunk is arrow IPC encoded RecordBatch that has
// rerun-specific semantic constraints and can be directly
// converted to a Rerun Chunk (`re_chunk::Chunk`)
message RerunChunk {
  // encoder version used to encode the data
  EncoderVersion encoder_version = 1;

  // Data payload is Arrow IPC encoded RecordBatch
  optional bytes payload = 2;
}

// uniquely identifies a table
message TableId {
  string id = 1;
}

// A recording can have multiple timelines, each is identified by a name, for example `log_tick`, `log_time`, etc.
message Timeline {
  string name = 1;
}

// A time range between start and end time points. Each 64 bit number can represent different time point data
// depending on the timeline it is associated with. Time range is inclusive for both start and end time points.
message TimeRange {
  int64 start = 1;
  int64 end = 2;
}

// arrow IPC serialized schema
message Schema {
  optional bytes arrow_schema = 1;
}

message IndexColumnSelector {
  // TODO(zehiko) we need to add support for other types of index selectors
  Timeline timeline = 1;
}

message IndexRange {
  // TODO(zehiko) support for other ranges for other index selectors
  TimeRange time_range = 1;
}

// The unique identifier of an entity, e.g. `camera/3/points`
// See <https://www.rerun.io/docs/concepts/entity-path> for more on entity paths.
message EntityPath {
  string path = 1;
}

message ApplicationId {
  string id = 1;
}

enum StoreKind {
  STORE_KIND_UNSPECIFIED = 0;
  STORE_KIND_RECORDING = 1;
  STORE_KIND_BLUEPRINT = 2;
}

message StoreId {
  // The kind of the store.
  StoreKind kind = 1;

  // The recording id of the store. For remote stores, this is the segment id. For blueprint store, this is an
  // arbitrary uuid.
  string recording_id = 2;

  // User-chosen name of the application doing the logging. For remote stores, this is the dataset entry id.
  rerun.common.v1alpha1.ApplicationId application_id = 3;
}

message Tuid {
  // Approximate nanoseconds since epoch.
  optional fixed64 time_ns = 1;

  // Initialized to something random on each thread, then incremented for each
  // new `Tuid` being allocated.
  optional fixed64 inc = 2;
}

message EntryId {
  Tuid id = 1;
}

// Entry point for all ManifestRegistryService APIs
message DatasetHandle {
  // Unique entry identifier (for debug purposes)
  EntryId entry_id = 1;

  // The kind of dataset this handle refers to.
  StoreKind store_kind = 3;

  // Path to Dataset backing storage (e.g. s3://bucket/file or file:///path/to/file)
  optional string dataset_url = 2;
}

// DataframePart is arrow IPC encoded RecordBatch
message DataframePart {
  // encoder version used to encode the data
  EncoderVersion encoder_version = 1;

  // Data payload is Arrow IPC encoded RecordBatch
  optional bytes payload = 2;

  // Compression used.
  //
  // This was introduced late in `DataframePart`'s lifetime, and therefore might be unspecified
  // in many real world recordings out there.
  // Unspecified is synonymous with uncompressed in this case.
  Compression compression = 3;

  // How large is the uncompressed data?
  //
  // The value is undefined if `self.compression == Off`.
  //
  // This was introduced late in `DataframePart`'s lifetime, and therefore might be unspecified
  // in many real world recordings out there (which is fine, because they are all implicitly
  // using `Compression::Off`).
  uint64 uncompressed_size = 4;
}

// Generic parameters that will influence the behavior of the Lance scanner.
//
// TODO(zehiko, cmc): This should be available for every endpoint that queries data in
// one way or another.
message ScanParameters {
  // List of columns to project. If empty, all columns will be projected.
  repeated string columns = 1;

  IfMissingBehavior on_missing_columns = 2;

  // An arbitrary filter expression that will be passed to the Lance scanner as-is.
  //
  // ```text
  // scanner.filter(filter)
  // ```
  optional string filter = 3;

  // An arbitrary offset that will be passed to the Lance scanner as-is.
  //
  // ```text
  // scanner.limit(_, limit_offset)
  // ```
  optional int64 limit_offset = 4;

  // An arbitrary limit that will be passed to the Lance scanner as-is.
  //
  // ```text
  // scanner.limit(limit_len, _)
  // ```
  optional int64 limit_len = 5;

  // An arbitrary order clause that will be passed to the Lance scanner as-is.
  //
  // ```text
  // scanner.order_by(â€¦)
  // ```
  repeated ScanParametersOrderClause order_by = 6;

  // If set, the output of `scanner.explain_plan` will be dumped to the server's log.
  bool explain_plan = 7;

  // If set, the final `scanner.filter` will be dumped to the server's log.
  bool explain_filter = 8;
}

enum IfMissingBehavior {
  IF_MISSING_BEHAVIOR_UNSPECIFIED = 0;
  IF_MISSING_BEHAVIOR_SKIP = 1;
  IF_MISSING_BEHAVIOR_ERROR = 2;
}

// Specify how the relevant creation call behaves
// in case of previously created (duplicate) items
enum IfDuplicateBehavior {
  IF_DUPLICATE_BEHAVIOR_UNSPECIFIED = 0;

  // Overwrite the existing item
  IF_DUPLICATE_BEHAVIOR_OVERWRITE = 1;

  // Skip if the item already exists
  IF_DUPLICATE_BEHAVIOR_SKIP = 2;

  // Return an error if the item already exists
  IF_DUPLICATE_BEHAVIOR_ERROR = 3;
}

message ScanParametersOrderClause {
  bool descending = 1;
  bool nulls_last = 2;
  optional string column_name = 3;
}

// Unique identifier for a segment. Can be user defined
// which means it can be of any type. For simplicity we start
// with a string, but we will probably revisit this.
message SegmentId {
  optional string id = 1;
}

message ComponentDescriptor {
  reserved 1;
  reserved "archetype_name";

  reserved 2;
  reserved "archetype_field_name";

  reserved 3;
  reserved "component_name";

  // Optional name of the `Archetype` associated with this data.
  optional string archetype = 4;

  // Identifier of the field within `Archetype` associated with this data.
  optional string component = 5;

  // Optional semantic name associated with this data.
  optional string component_type = 6;
}

// Unique identifier of a task submitted in the redap
// tasks subsystem
message TaskId {
  string id = 1;
}

// Mirrors `re_build_info::BuildInfo`.
message BuildInfo {
  // `CARGO_PKG_NAME`.
  optional string crate_name = 1;

  // Space-separated names of all features enabled for this crate.
  optional string features = 2;

  // Crate version, parsed from `CARGO_PKG_VERSION`, ignoring any `+metadata` suffix.
  optional SemanticVersion version = 3;

  // The raw version string of the Rust compiler used, or an empty string.
  optional string rustc_version = 4;

  // The raw version string of the LLVM toolchain used, or an empty string.
  optional string llvm_version = 5;

  // Git commit hash, or empty string.
  optional string git_hash = 6;

  // Current git branch, or empty string.
  optional string git_branch = 7;

  // Target architecture and OS
  //
  // Example: `xaarch64-apple-darwin`
  optional string target_triple = 8;

  // ISO 8601 / RFC 3339 build time.
  //
  // Example: `"2023-02-23T19:33:26Z"`
  //
  // Empty if unknown.
  optional string build_time = 9;

  /// True if this is a debug build.
  optional bool is_debug_build = 10;
}

// Mirrors `re_build_info::CrateVersion`.
message SemanticVersion {
  optional fixed32 major = 1;

  optional fixed32 minor = 2;

  optional fixed32 patch = 3;

  oneof meta {
    fixed32 rc = 4;
    fixed32 alpha = 5;
    DevAlpha dev_alpha = 6;
  }
}

// Mirrors `re_build_info::DevAlpha`.
message DevAlpha {
  optional fixed32 alpha = 1;
  optional string commit = 2;
}
