# DO NOT EDIT! This file was auto-generated by crates/build/re_types_builder/src/codegen/python/mod.rs
# Based on "crates/store/re_sdk_types/definitions/rerun/testing/components/fuzzy_deps.fbs".

# You can extend this class by creating a "StringComponentExt" class in "string_component_ext.py".

from __future__ import annotations

from collections.abc import Sequence
from typing import Any

import numpy as np
import pyarrow as pa
from attrs import define, field
from rerun._baseclasses import (
    BaseBatch,
)

__all__ = ["StringComponent", "StringComponentArrayLike", "StringComponentBatch", "StringComponentLike"]


@define(init=False)
class StringComponent:
    def __init__(self: Any, value: StringComponentLike) -> None:
        """Create a new instance of the StringComponent datatype."""

        # You can define your own __init__ function as a member of StringComponentExt in string_component_ext.py
        self.__attrs_init__(value=value)

    value: str = field(converter=str)

    def __str__(self) -> str:
        return str(self.value)

    def __hash__(self) -> int:
        return hash(self.value)


StringComponentLike = StringComponent
"""A type alias for any StringComponent-like object."""

StringComponentArrayLike = StringComponent | Sequence[StringComponentLike]
"""A type alias for any StringComponent-like array object."""


class StringComponentBatch(BaseBatch[StringComponentArrayLike]):
    _ARROW_DATATYPE = pa.utf8()

    @staticmethod
    def _native_to_pa_array(data: StringComponentArrayLike, data_type: pa.DataType) -> pa.Array:
        _ = data_type  # unused: conversion handled on Rust side

        if isinstance(data, str):
            strings: list[str] = [data]
        elif isinstance(data, Sequence):
            strings = [str(datum) for datum in data]
        elif isinstance(data, np.ndarray):
            strings = [str(x) for x in data]
        else:
            strings = [str(data)]

        encoded = [s.encode("utf-8") for s in strings]
        offsets = np.empty(len(encoded) + 1, dtype=np.int32)
        offsets[0] = 0
        for i, e in enumerate(encoded):
            offsets[i + 1] = offsets[i] + len(e)
        data_bytes = np.frombuffer(b"".join(encoded), dtype=np.uint8) if encoded else np.array([], dtype=np.uint8)
        return (data_bytes, offsets, -1)
