# DO NOT EDIT! This file was auto-generated by crates/build/re_types_builder/src/codegen/python/mod.rs
# Based on "crates/store/re_types/definitions/rerun/datatypes/text_log_column.fbs".

# You can extend this class by creating a "TextLogColumnKindExt" class in "text_log_column_kind_ext.py".

from __future__ import annotations

from typing import TYPE_CHECKING, Any, Literal

import pyarrow as pa
from attrs import define, field

from .. import datatypes
from .._baseclasses import (
    BaseBatch,
)

__all__ = ["TextLogColumnKind", "TextLogColumnKindArrayLike", "TextLogColumnKindBatch", "TextLogColumnKindLike"]


@define
class TextLogColumnKind:
    """**Datatype**: A text log column kind."""

    # You can define your own __init__ function as a member of TextLogColumnKindExt in text_log_column_kind_ext.py

    inner: None | datatypes.Utf8 = field()
    """
    Must be one of:

    * Timeline (datatypes.Utf8):
        A specific timeline's column.

    * EntityPath (None):
        Column for which entity path this was logged to.

    * LogLevel (None):
        Column for log-level.

    * Body (None):
        The text message the log has.
    """

    kind: Literal["timeline", "entity_path", "log_level", "body"] = field(default="timeline")
    """
    Possible values:

    * "timeline":
        A specific timeline's column.

    * "entity_path":
        Column for which entity path this was logged to.

    * "log_level":
        Column for log-level.

    * "body":
        The text message the log has.
    """


if TYPE_CHECKING:
    from collections.abc import Sequence

    TextLogColumnKindLike = TextLogColumnKind | None | datatypes.Utf8
    """A type alias for any TextLogColumnKind-like object."""

    TextLogColumnKindArrayLike = TextLogColumnKind | None | datatypes.Utf8 | Sequence[TextLogColumnKindLike]
    """A type alias for any TextLogColumnKind-like array object."""
else:
    TextLogColumnKindLike = Any
    TextLogColumnKindArrayLike = Any


class TextLogColumnKindBatch(BaseBatch[TextLogColumnKindArrayLike]):
    _ARROW_DATATYPE = pa.dense_union([
        pa.field("_null_markers", pa.null(), nullable=True, metadata={}),
        pa.field("Timeline", pa.utf8(), nullable=False, metadata={}),
        pa.field("EntityPath", pa.null(), nullable=True, metadata={}),
        pa.field("LogLevel", pa.null(), nullable=True, metadata={}),
        pa.field("Body", pa.null(), nullable=True, metadata={}),
    ])

    @staticmethod
    def _native_to_pa_array(data: TextLogColumnKindArrayLike, data_type: pa.DataType) -> pa.Array:
        from typing import cast

        from rerun.datatypes import Utf8Batch

        if not hasattr(data, "__iter__") or isinstance(data, (type(None), TextLogColumnKind, datatypes.Utf8)):  # type: ignore[arg-type]
            data = [data]  # type: ignore[list-item]
        data = cast("Sequence[TextLogColumnKindLike]", data)  # type: ignore[redundant-cast]

        types: list[int] = []
        value_offsets: list[int] = []

        num_nulls = 0
        variant_timeline: list[datatypes.Utf8] = []
        variant_entity_path: int = 0
        variant_log_level: int = 0
        variant_body: int = 0

        for value in data:
            if value is None:
                value_offsets.append(num_nulls)
                num_nulls += 1
                types.append(0)
            else:
                if not isinstance(value, TextLogColumnKind):
                    value = TextLogColumnKind(value)
                if value.kind == "timeline":
                    value_offsets.append(len(variant_timeline))
                    variant_timeline.append(value.inner)  # type: ignore[arg-type]
                    types.append(1)
                elif value.kind == "entity_path":
                    value_offsets.append(variant_entity_path)
                    variant_entity_path += 1
                    types.append(2)
                elif value.kind == "log_level":
                    value_offsets.append(variant_log_level)
                    variant_log_level += 1
                    types.append(3)
                elif value.kind == "body":
                    value_offsets.append(variant_body)
                    variant_body += 1
                    types.append(4)

        buffers = [
            None,
            pa.array(types, type=pa.int8()).buffers()[1],
            pa.array(value_offsets, type=pa.int32()).buffers()[1],
        ]
        children = [
            pa.nulls(num_nulls),
            Utf8Batch(variant_timeline).as_arrow_array(),
            pa.nulls(variant_entity_path),
            pa.nulls(variant_log_level),
            pa.nulls(variant_body),
        ]

        return pa.UnionArray.from_buffers(
            type=data_type,
            length=len(data),
            buffers=buffers,
            children=children,
        )
