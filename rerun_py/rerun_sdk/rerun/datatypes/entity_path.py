# DO NOT EDIT! This file was auto-generated by crates/build/re_types_builder/src/codegen/python/mod.rs
# Based on "crates/store/re_sdk_types/definitions/rerun/datatypes/entity_path.fbs".

# You can extend this class by creating a "EntityPathExt" class in "entity_path_ext.py".

from __future__ import annotations

from collections.abc import Sequence
from typing import TYPE_CHECKING, Any

import numpy as np
import pyarrow as pa
from attrs import define, field

from .._baseclasses import (
    BaseBatch,
)

__all__ = ["EntityPath", "EntityPathArrayLike", "EntityPathBatch", "EntityPathLike"]


@define(init=False)
class EntityPath:
    """**Datatype**: A path to an entity in the `ChunkStore`."""

    def __init__(self: Any, path: EntityPathLike) -> None:
        """Create a new instance of the EntityPath datatype."""

        # You can define your own __init__ function as a member of EntityPathExt in entity_path_ext.py
        self.__attrs_init__(path=path)

    path: str = field(converter=str)

    def __str__(self) -> str:
        return str(self.path)

    def __hash__(self) -> int:
        return hash(self.path)


if TYPE_CHECKING:
    EntityPathLike = EntityPath | str
    """A type alias for any EntityPath-like object."""
else:
    EntityPathLike = Any

EntityPathArrayLike = EntityPath | Sequence[EntityPathLike] | Sequence[str]
"""A type alias for any EntityPath-like array object."""


class EntityPathBatch(BaseBatch[EntityPathArrayLike]):
    _ARROW_DATATYPE = pa.utf8()

    @staticmethod
    def _native_to_pa_array(data: EntityPathArrayLike, data_type: pa.DataType) -> pa.Array:
        _ = data_type  # unused: conversion handled on Rust side

        if isinstance(data, str):
            strings: list[str] = [data]
        elif isinstance(data, Sequence):
            strings = [str(datum) for datum in data]
        elif isinstance(data, np.ndarray):
            strings = [str(x) for x in data]
        else:
            strings = [str(data)]

        encoded = [s.encode("utf-8") for s in strings]
        offsets = np.empty(len(encoded) + 1, dtype=np.int32)
        offsets[0] = 0
        for i, e in enumerate(encoded):
            offsets[i + 1] = offsets[i] + len(e)
        data_bytes = np.frombuffer(b"".join(encoded), dtype=np.uint8) if encoded else np.array([], dtype=np.uint8)
        return (data_bytes, offsets, -1)
