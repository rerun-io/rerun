# DO NOT EDIT! This file was auto-generated by crates/build/re_types_builder/src/codegen/python/mod.rs
# Based on "crates/store/re_sdk_types/definitions/rerun/datatypes/utf8.fbs".

# You can extend this class by creating a "Utf8Ext" class in "utf8_ext.py".

from __future__ import annotations

from collections.abc import Sequence
from typing import TYPE_CHECKING, Any

import numpy as np
import numpy.typing as npt
import pyarrow as pa
from attrs import define, field

from .._baseclasses import (
    BaseBatch,
)

__all__ = ["Utf8", "Utf8ArrayLike", "Utf8Batch", "Utf8Like"]


@define(init=False)
class Utf8:
    """**Datatype**: A string of text, encoded as UTF-8."""

    def __init__(self: Any, value: Utf8Like) -> None:
        """Create a new instance of the Utf8 datatype."""

        # You can define your own __init__ function as a member of Utf8Ext in utf8_ext.py
        self.__attrs_init__(value=value)

    value: str = field(converter=str)

    def __str__(self) -> str:
        return str(self.value)

    def __hash__(self) -> int:
        return hash(self.value)


if TYPE_CHECKING:
    Utf8Like = Utf8 | str
    """A type alias for any Utf8-like object."""
else:
    Utf8Like = Any

Utf8ArrayLike = Utf8 | Sequence[Utf8Like] | str | Sequence[str] | npt.ArrayLike
"""A type alias for any Utf8-like array object."""


class Utf8Batch(BaseBatch[Utf8ArrayLike]):
    _ARROW_DATATYPE = pa.utf8()

    @staticmethod
    def _native_to_pa_array(data: Utf8ArrayLike, data_type: pa.DataType) -> pa.Array:
        _ = data_type  # unused: conversion handled on Rust side

        if isinstance(data, str):
            strings: list[str] = [data]
        elif isinstance(data, Sequence):
            strings = [str(datum) for datum in data]
        elif isinstance(data, np.ndarray):
            strings = [str(x) for x in data]
        else:
            strings = [str(data)]

        encoded = [s.encode("utf-8") for s in strings]
        offsets = np.empty(len(encoded) + 1, dtype=np.int32)
        offsets[0] = 0
        for i, e in enumerate(encoded):
            offsets[i + 1] = offsets[i] + len(e)
        data_bytes = np.frombuffer(b"".join(encoded), dtype=np.uint8) if encoded else np.array([], dtype=np.uint8)
        return (data_bytes, offsets, -1)
