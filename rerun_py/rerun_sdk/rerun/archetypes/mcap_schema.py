# DO NOT EDIT! This file was auto-generated by crates/build/re_types_builder/src/codegen/python/mod.rs
# Based on "crates/store/re_types/definitions/rerun/archetypes/mcap_schema.fbs".

# You can extend this class by creating a "McapSchemaExt" class in "mcap_schema_ext.py".

from __future__ import annotations

from typing import Any

import numpy as np
import pyarrow as pa
from attrs import define, field

from .. import components, datatypes
from .._baseclasses import (
    Archetype,
    ComponentColumnList,
)
from ..error_utils import catch_and_log_exceptions

__all__ = ["McapSchema"]


@define(str=False, repr=False, init=False)
class McapSchema(Archetype):
    """
    **Archetype**: Information about an MCAP schema definition.

    This archetype stores schema metadata including the schema ID, name, encoding format,
    and the raw schema data itself.

    See also [MCAP specification](https://mcap.dev/) for more details on the format.

    ⚠️ **This type is _unstable_ and may change significantly in a way that the data won't be backwards compatible.**
    """

    def __init__(
        self: Any,
        id: datatypes.UInt16Like,
        name: datatypes.Utf8Like,
        encoding: datatypes.Utf8Like,
        data: datatypes.BlobLike,
    ) -> None:
        """
        Create a new instance of the McapSchema archetype.

        Parameters
        ----------
        id:
            The schema ID within the MCAP file.
        name:
            The name of this schema.
        encoding:
            The encoding format used by this schema (e.g., "protobuf", "ros1msg", "jsonschema").
        data:
            The raw schema data as binary content.

        """

        # You can define your own __init__ function as a member of McapSchemaExt in mcap_schema_ext.py
        with catch_and_log_exceptions(context=self.__class__.__name__):
            self.__attrs_init__(id=id, name=name, encoding=encoding, data=data)
            return
        self.__attrs_clear__()

    def __attrs_clear__(self) -> None:
        """Convenience method for calling `__attrs_init__` with all `None`s."""
        self.__attrs_init__(
            id=None,
            name=None,
            encoding=None,
            data=None,
        )

    @classmethod
    def _clear(cls) -> McapSchema:
        """Produce an empty McapSchema, bypassing `__init__`."""
        inst = cls.__new__(cls)
        inst.__attrs_clear__()
        return inst

    @classmethod
    def from_fields(
        cls,
        *,
        clear_unset: bool = False,
        id: datatypes.UInt16Like | None = None,
        name: datatypes.Utf8Like | None = None,
        encoding: datatypes.Utf8Like | None = None,
        data: datatypes.BlobLike | None = None,
    ) -> McapSchema:
        """
        Update only some specific fields of a `McapSchema`.

        Parameters
        ----------
        clear_unset:
            If true, all unspecified fields will be explicitly cleared.
        id:
            The schema ID within the MCAP file.
        name:
            The name of this schema.
        encoding:
            The encoding format used by this schema (e.g., "protobuf", "ros1msg", "jsonschema").
        data:
            The raw schema data as binary content.

        """

        inst = cls.__new__(cls)
        with catch_and_log_exceptions(context=cls.__name__):
            kwargs = {
                "id": id,
                "name": name,
                "encoding": encoding,
                "data": data,
            }

            if clear_unset:
                kwargs = {k: v if v is not None else [] for k, v in kwargs.items()}  # type: ignore[misc]

            inst.__attrs_init__(**kwargs)
            return inst

        inst.__attrs_clear__()
        return inst

    @classmethod
    def cleared(cls) -> McapSchema:
        """Clear all the fields of a `McapSchema`."""
        return cls.from_fields(clear_unset=True)

    @classmethod
    def columns(
        cls,
        *,
        id: datatypes.UInt16ArrayLike | None = None,
        name: datatypes.Utf8ArrayLike | None = None,
        encoding: datatypes.Utf8ArrayLike | None = None,
        data: datatypes.BlobArrayLike | None = None,
    ) -> ComponentColumnList:
        """
        Construct a new column-oriented component bundle.

        This makes it possible to use `rr.send_columns` to send columnar data directly into Rerun.

        The returned columns will be partitioned into unit-length sub-batches by default.
        Use `ComponentColumnList.partition` to repartition the data as needed.

        Parameters
        ----------
        id:
            The schema ID within the MCAP file.
        name:
            The name of this schema.
        encoding:
            The encoding format used by this schema (e.g., "protobuf", "ros1msg", "jsonschema").
        data:
            The raw schema data as binary content.

        """

        inst = cls.__new__(cls)
        with catch_and_log_exceptions(context=cls.__name__):
            inst.__attrs_init__(
                id=id,
                name=name,
                encoding=encoding,
                data=data,
            )

        batches = inst.as_component_batches()
        if len(batches) == 0:
            return ComponentColumnList([])

        kwargs = {
            "McapSchema:id": id,
            "McapSchema:name": name,
            "McapSchema:encoding": encoding,
            "McapSchema:data": data,
        }
        columns = []

        for batch in batches:
            arrow_array = batch.as_arrow_array()

            # For primitive arrays and fixed size list arrays, we infer partition size from the input shape.
            if pa.types.is_primitive(arrow_array.type) or pa.types.is_fixed_size_list(arrow_array.type):
                param = kwargs[batch.component_descriptor().component]  # type: ignore[index]
                shape = np.shape(param)  # type: ignore[arg-type]
                elem_flat_len = int(np.prod(shape[1:])) if len(shape) > 1 else 1  # type: ignore[redundant-expr,misc]

                if pa.types.is_fixed_size_list(arrow_array.type) and arrow_array.type.list_size == elem_flat_len:
                    # If the product of the last dimensions of the shape are equal to the size of the fixed size list array,
                    # we have `num_rows` single element batches (each element is a fixed sized list).
                    # (This should have been already validated by conversion to the arrow_array)
                    batch_length = 1
                else:
                    batch_length = shape[1] if len(shape) > 1 else 1  # type: ignore[redundant-expr,misc]

                num_rows = shape[0] if len(shape) >= 1 else 1  # type: ignore[redundant-expr,misc]
                sizes = batch_length * np.ones(num_rows)
            else:
                # For non-primitive types, default to partitioning each element separately.
                sizes = np.ones(len(arrow_array))

            columns.append(batch.partition(sizes))

        return ComponentColumnList(columns)

    id: components.ChannelIdBatch | None = field(
        metadata={"component": True},
        default=None,
        converter=components.ChannelIdBatch._converter,  # type: ignore[misc]
    )
    # The schema ID within the MCAP file.
    #
    # (Docstring intentionally commented out to hide this field from the docs)

    name: components.TextBatch | None = field(
        metadata={"component": True},
        default=None,
        converter=components.TextBatch._converter,  # type: ignore[misc]
    )
    # The name of this schema.
    #
    # (Docstring intentionally commented out to hide this field from the docs)

    encoding: components.TextBatch | None = field(
        metadata={"component": True},
        default=None,
        converter=components.TextBatch._converter,  # type: ignore[misc]
    )
    # The encoding format used by this schema (e.g., "protobuf", "ros1msg", "jsonschema").
    #
    # (Docstring intentionally commented out to hide this field from the docs)

    data: components.BlobBatch | None = field(
        metadata={"component": True},
        default=None,
        converter=components.BlobBatch._converter,  # type: ignore[misc]
    )
    # The raw schema data as binary content.
    #
    # (Docstring intentionally commented out to hide this field from the docs)

    __str__ = Archetype.__str__
    __repr__ = Archetype.__repr__  # type: ignore[assignment]
