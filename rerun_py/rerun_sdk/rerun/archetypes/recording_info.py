# DO NOT EDIT! This file was auto-generated by crates/build/re_types_builder/src/codegen/python/mod.rs
# Based on "crates/store/re_types/definitions/rerun/archetypes/recording_info.fbs".

# You can extend this class by creating a "RecordingInfoExt" class in "recording_info_ext.py".

from __future__ import annotations

from typing import Any

import numpy as np
import pyarrow as pa
from attrs import define, field

from .. import components, datatypes
from .._baseclasses import (
    Archetype,
    ComponentColumnList,
)
from ..error_utils import catch_and_log_exceptions

__all__ = ["RecordingInfo"]


@define(str=False, repr=False, init=False)
class RecordingInfo(Archetype):
    """**Archetype**: A list of properties associated with a recording."""

    def __init__(
        self: Any, *, start_time: datatypes.TimeIntLike | None = None, name: datatypes.Utf8Like | None = None
    ) -> None:
        """
        Create a new instance of the RecordingInfo archetype.

        Parameters
        ----------
        start_time:
            When the recording started.

            Should be an absolute time, i.e. relative to Unix Epoch.
        name:
            A user-chosen name for the recording.

        """

        # You can define your own __init__ function as a member of RecordingInfoExt in recording_info_ext.py
        with catch_and_log_exceptions(context=self.__class__.__name__):
            self.__attrs_init__(start_time=start_time, name=name)
            return
        self.__attrs_clear__()

    def __attrs_clear__(self) -> None:
        """Convenience method for calling `__attrs_init__` with all `None`s."""
        self.__attrs_init__(
            start_time=None,
            name=None,
        )

    @classmethod
    def _clear(cls) -> RecordingInfo:
        """Produce an empty RecordingInfo, bypassing `__init__`."""
        inst = cls.__new__(cls)
        inst.__attrs_clear__()
        return inst

    @classmethod
    def from_fields(
        cls,
        *,
        clear_unset: bool = False,
        start_time: datatypes.TimeIntLike | None = None,
        name: datatypes.Utf8Like | None = None,
    ) -> RecordingInfo:
        """
        Update only some specific fields of a `RecordingInfo`.

        Parameters
        ----------
        clear_unset:
            If true, all unspecified fields will be explicitly cleared.
        start_time:
            When the recording started.

            Should be an absolute time, i.e. relative to Unix Epoch.
        name:
            A user-chosen name for the recording.

        """

        inst = cls.__new__(cls)
        with catch_and_log_exceptions(context=cls.__name__):
            kwargs = {
                "start_time": start_time,
                "name": name,
            }

            if clear_unset:
                kwargs = {k: v if v is not None else [] for k, v in kwargs.items()}  # type: ignore[misc]

            inst.__attrs_init__(**kwargs)
            return inst

        inst.__attrs_clear__()
        return inst

    @classmethod
    def cleared(cls) -> RecordingInfo:
        """Clear all the fields of a `RecordingInfo`."""
        return cls.from_fields(clear_unset=True)

    @classmethod
    def columns(
        cls,
        *,
        start_time: datatypes.TimeIntArrayLike | None = None,
        name: datatypes.Utf8ArrayLike | None = None,
    ) -> ComponentColumnList:
        """
        Construct a new column-oriented component bundle.

        This makes it possible to use `rr.send_columns` to send columnar data directly into Rerun.

        The returned columns will be partitioned into unit-length sub-batches by default.
        Use `ComponentColumnList.partition` to repartition the data as needed.

        Parameters
        ----------
        start_time:
            When the recording started.

            Should be an absolute time, i.e. relative to Unix Epoch.
        name:
            A user-chosen name for the recording.

        """

        inst = cls.__new__(cls)
        with catch_and_log_exceptions(context=cls.__name__):
            inst.__attrs_init__(
                start_time=start_time,
                name=name,
            )

        batches = inst.as_component_batches()
        if len(batches) == 0:
            return ComponentColumnList([])

        kwargs = {"RecordingInfo:start_time": start_time, "RecordingInfo:name": name}
        columns = []

        for batch in batches:
            arrow_array = batch.as_arrow_array()

            # For primitive arrays and fixed size list arrays, we infer partition size from the input shape.
            if pa.types.is_primitive(arrow_array.type) or pa.types.is_fixed_size_list(arrow_array.type):
                param = kwargs[batch.component_descriptor().component]  # type: ignore[index]
                shape = np.shape(param)  # type: ignore[arg-type]
                elem_flat_len = int(np.prod(shape[1:])) if len(shape) > 1 else 1  # type: ignore[redundant-expr,misc]

                if pa.types.is_fixed_size_list(arrow_array.type) and arrow_array.type.list_size == elem_flat_len:
                    # If the product of the last dimensions of the shape are equal to the size of the fixed size list array,
                    # we have `num_rows` single element batches (each element is a fixed sized list).
                    # (This should have been already validated by conversion to the arrow_array)
                    batch_length = 1
                else:
                    batch_length = shape[1] if len(shape) > 1 else 1  # type: ignore[redundant-expr,misc]

                num_rows = shape[0] if len(shape) >= 1 else 1  # type: ignore[redundant-expr,misc]
                sizes = batch_length * np.ones(num_rows)
            else:
                # For non-primitive types, default to partitioning each element separately.
                sizes = np.ones(len(arrow_array))

            columns.append(batch.partition(sizes))

        return ComponentColumnList(columns)

    start_time: components.TimestampBatch | None = field(
        metadata={"component": True},
        default=None,
        converter=components.TimestampBatch._converter,  # type: ignore[misc]
    )
    # When the recording started.
    #
    # Should be an absolute time, i.e. relative to Unix Epoch.
    #
    # (Docstring intentionally commented out to hide this field from the docs)

    name: components.NameBatch | None = field(
        metadata={"component": True},
        default=None,
        converter=components.NameBatch._converter,  # type: ignore[misc]
    )
    # A user-chosen name for the recording.
    #
    # (Docstring intentionally commented out to hide this field from the docs)

    __str__ = Archetype.__str__
    __repr__ = Archetype.__repr__  # type: ignore[assignment]
