# DO NOT EDIT! This file was auto-generated by crates/build/re_types_builder/src/codegen/python/mod.rs
# Based on "crates/store/re_types/definitions/rerun/archetypes/video_stream.fbs".

# You can extend this class by creating a "VideoStreamExt" class in "video_stream_ext.py".

from __future__ import annotations

from typing import Any

import numpy as np
import pyarrow as pa
from attrs import define, field

from .. import components, datatypes
from .._baseclasses import (
    Archetype,
    ComponentColumnList,
)
from ..error_utils import catch_and_log_exceptions

__all__ = ["VideoStream"]


@define(str=False, repr=False, init=False)
class VideoStream(Archetype):
    """
    **Archetype**: Video stream consisting of raw video chunks.

    For logging video containers like mp4, refer to [`archetypes.AssetVideo`][rerun.archetypes.AssetVideo] and [`archetypes.VideoFrameReference`][rerun.archetypes.VideoFrameReference].
    To learn more about video support in Rerun, check the [video reference](https://rerun.io/docs/reference/video).

    All components except `sample` are typically logged statically once per entity.
    `sample` is then logged repeatedly for each frame on the timeline.

    TODO(#10422): [`archetypes.VideoFrameReference`][rerun.archetypes.VideoFrameReference] does not yet work with [`archetypes.VideoStream`][rerun.archetypes.VideoStream].

    ⚠️ **This type is _unstable_ and may change significantly in a way that the data won't be backwards compatible.**

    Example
    -------
    ### Live streaming of on-the-fly encoded video:
    ```python
    import av
    import numpy as np
    import numpy.typing as npt
    import rerun as rr

    fps = 30
    duration_seconds = 4
    width = 480
    height = 320
    ball_radius = 30


    def create_example_video_frame(frame_i: int) -> npt.NDArray[np.uint8]:
        img = np.zeros((height, width, 3), dtype=np.uint8)
        for h in range(height):
            img[h, :] = [0, int(100 * h / height), int(200 * h / height)]  # Blue to purple gradient.

        x_pos = width // 2  # Center horizontally.
        y_pos = height // 2 + 80 * np.sin(2 * np.pi * frame_i / fps)
        y, x = np.ogrid[:height, :width]
        r_sq = (x - x_pos) ** 2 + (y - y_pos) ** 2
        img[r_sq < ball_radius**2] = [255, 200, 0]  # Gold color

        return img


    rr.init("rerun_example_video_stream_synthetic", spawn=True)

    # Setup encoding pipeline.
    av.logging.set_level(av.logging.VERBOSE)
    container = av.open("/dev/null", "w", format="h264")  # Use AnnexB H.264 stream.
    stream = container.add_stream("libx264", rate=fps)
    # Type narrowing
    assert isinstance(stream, av.video.stream.VideoStream)
    stream.width = width
    stream.height = height
    # TODO(#10090): Rerun Video Streams don't support b-frames yet.
    # Note that b-frames are generally not recommended for low-latency streaming and may make logging more complex.
    stream.max_b_frames = 0

    # Log codec only once as static data (it naturally never changes). This isn't strictly necessary, but good practice.
    rr.log("video_stream", rr.VideoStream(codec=rr.VideoCodec.H264), static=True)

    # Generate frames and stream them directly to Rerun.
    for frame_i in range(fps * duration_seconds):
        img = create_example_video_frame(frame_i)
        frame = av.VideoFrame.from_ndarray(img, format="rgb24")
        for packet in stream.encode(frame):
            if packet.pts is None:
                continue
            rr.set_time("time", duration=float(packet.pts * packet.time_base))
            rr.log("video_stream", rr.VideoStream.from_fields(sample=bytes(packet)))

    # Flush stream.
    for packet in stream.encode():
        if packet.pts is None:
            continue
        rr.set_time("time", duration=float(packet.pts * packet.time_base))
        rr.log("video_stream", rr.VideoStream.from_fields(sample=bytes(packet)))
    ```
    <center>
    <picture>
      <source media="(max-width: 480px)" srcset="https://static.rerun.io/video_stream_synthetic/4dd34da01980afa5604994fa4cce34d7573b0763/480w.png">
      <source media="(max-width: 768px)" srcset="https://static.rerun.io/video_stream_synthetic/4dd34da01980afa5604994fa4cce34d7573b0763/768w.png">
      <source media="(max-width: 1024px)" srcset="https://static.rerun.io/video_stream_synthetic/4dd34da01980afa5604994fa4cce34d7573b0763/1024w.png">
      <source media="(max-width: 1200px)" srcset="https://static.rerun.io/video_stream_synthetic/4dd34da01980afa5604994fa4cce34d7573b0763/1200w.png">
      <img src="https://static.rerun.io/video_stream_synthetic/4dd34da01980afa5604994fa4cce34d7573b0763/full.png" width="640">
    </picture>
    </center>

    """

    def __init__(
        self: Any,
        codec: components.VideoCodecLike,
        *,
        sample: datatypes.BlobLike | None = None,
        draw_order: datatypes.Float32Like | None = None,
    ) -> None:
        """
        Create a new instance of the VideoStream archetype.

        Parameters
        ----------
        codec:
            The codec used to encode the video chunks.

            This property is expected to be constant over time and is ideally logged statically once per stream.
        sample:
            Video sample data (also known as "video chunk").

            The current timestamp is used as presentation timestamp (PTS) for all data in this sample.
            There is currently no way to log differing decoding timestamps, meaning
            that there is no support for B-frames.
            See <https://github.com/rerun-io/rerun/issues/10090> for more details.

            Unlike any other data in Rerun, video samples are not allowed to be logged out of order,
            as this may break live video playback.
            I.e. any appended sample should have a timestamp greater than all previously logged samples.

            The samples are expected to be encoded using the `codec` field.
            Each video sample must contain enough data for exactly one video frame
            (this restriction may be relaxed in the future for some codecs).

            Unless your stream consists entirely of key-frames (in which case you should consider [`archetypes.EncodedImage`][rerun.archetypes.EncodedImage])
            never log this component as static data as this means that you loose all information of
            previous samples which may be required to decode an image.

            See [`components.VideoCodec`][rerun.components.VideoCodec] for codec specific requirements.
        draw_order:
            An optional floating point value that specifies the 2D drawing order.

            Objects with higher values are drawn on top of those with lower values.
            Defaults to `-15.0`.

        """

        # You can define your own __init__ function as a member of VideoStreamExt in video_stream_ext.py
        with catch_and_log_exceptions(context=self.__class__.__name__):
            self.__attrs_init__(codec=codec, sample=sample, draw_order=draw_order)
            return
        self.__attrs_clear__()

    def __attrs_clear__(self) -> None:
        """Convenience method for calling `__attrs_init__` with all `None`s."""
        self.__attrs_init__(
            codec=None,
            sample=None,
            draw_order=None,
        )

    @classmethod
    def _clear(cls) -> VideoStream:
        """Produce an empty VideoStream, bypassing `__init__`."""
        inst = cls.__new__(cls)
        inst.__attrs_clear__()
        return inst

    @classmethod
    def from_fields(
        cls,
        *,
        clear_unset: bool = False,
        codec: components.VideoCodecLike | None = None,
        sample: datatypes.BlobLike | None = None,
        draw_order: datatypes.Float32Like | None = None,
    ) -> VideoStream:
        """
        Update only some specific fields of a `VideoStream`.

        Parameters
        ----------
        clear_unset:
            If true, all unspecified fields will be explicitly cleared.
        codec:
            The codec used to encode the video chunks.

            This property is expected to be constant over time and is ideally logged statically once per stream.
        sample:
            Video sample data (also known as "video chunk").

            The current timestamp is used as presentation timestamp (PTS) for all data in this sample.
            There is currently no way to log differing decoding timestamps, meaning
            that there is no support for B-frames.
            See <https://github.com/rerun-io/rerun/issues/10090> for more details.

            Unlike any other data in Rerun, video samples are not allowed to be logged out of order,
            as this may break live video playback.
            I.e. any appended sample should have a timestamp greater than all previously logged samples.

            The samples are expected to be encoded using the `codec` field.
            Each video sample must contain enough data for exactly one video frame
            (this restriction may be relaxed in the future for some codecs).

            Unless your stream consists entirely of key-frames (in which case you should consider [`archetypes.EncodedImage`][rerun.archetypes.EncodedImage])
            never log this component as static data as this means that you loose all information of
            previous samples which may be required to decode an image.

            See [`components.VideoCodec`][rerun.components.VideoCodec] for codec specific requirements.
        draw_order:
            An optional floating point value that specifies the 2D drawing order.

            Objects with higher values are drawn on top of those with lower values.
            Defaults to `-15.0`.

        """

        inst = cls.__new__(cls)
        with catch_and_log_exceptions(context=cls.__name__):
            kwargs = {
                "codec": codec,
                "sample": sample,
                "draw_order": draw_order,
            }

            if clear_unset:
                kwargs = {k: v if v is not None else [] for k, v in kwargs.items()}  # type: ignore[misc]

            inst.__attrs_init__(**kwargs)
            return inst

        inst.__attrs_clear__()
        return inst

    @classmethod
    def cleared(cls) -> VideoStream:
        """Clear all the fields of a `VideoStream`."""
        return cls.from_fields(clear_unset=True)

    @classmethod
    def columns(
        cls,
        *,
        codec: components.VideoCodecArrayLike | None = None,
        sample: datatypes.BlobArrayLike | None = None,
        draw_order: datatypes.Float32ArrayLike | None = None,
    ) -> ComponentColumnList:
        """
        Construct a new column-oriented component bundle.

        This makes it possible to use `rr.send_columns` to send columnar data directly into Rerun.

        The returned columns will be partitioned into unit-length sub-batches by default.
        Use `ComponentColumnList.partition` to repartition the data as needed.

        Parameters
        ----------
        codec:
            The codec used to encode the video chunks.

            This property is expected to be constant over time and is ideally logged statically once per stream.
        sample:
            Video sample data (also known as "video chunk").

            The current timestamp is used as presentation timestamp (PTS) for all data in this sample.
            There is currently no way to log differing decoding timestamps, meaning
            that there is no support for B-frames.
            See <https://github.com/rerun-io/rerun/issues/10090> for more details.

            Unlike any other data in Rerun, video samples are not allowed to be logged out of order,
            as this may break live video playback.
            I.e. any appended sample should have a timestamp greater than all previously logged samples.

            The samples are expected to be encoded using the `codec` field.
            Each video sample must contain enough data for exactly one video frame
            (this restriction may be relaxed in the future for some codecs).

            Unless your stream consists entirely of key-frames (in which case you should consider [`archetypes.EncodedImage`][rerun.archetypes.EncodedImage])
            never log this component as static data as this means that you loose all information of
            previous samples which may be required to decode an image.

            See [`components.VideoCodec`][rerun.components.VideoCodec] for codec specific requirements.
        draw_order:
            An optional floating point value that specifies the 2D drawing order.

            Objects with higher values are drawn on top of those with lower values.
            Defaults to `-15.0`.

        """

        inst = cls.__new__(cls)
        with catch_and_log_exceptions(context=cls.__name__):
            inst.__attrs_init__(
                codec=codec,
                sample=sample,
                draw_order=draw_order,
            )

        batches = inst.as_component_batches()
        if len(batches) == 0:
            return ComponentColumnList([])

        kwargs = {"VideoStream:codec": codec, "VideoStream:sample": sample, "VideoStream:draw_order": draw_order}
        columns = []

        for batch in batches:
            arrow_array = batch.as_arrow_array()

            # For primitive arrays and fixed size list arrays, we infer partition size from the input shape.
            if pa.types.is_primitive(arrow_array.type) or pa.types.is_fixed_size_list(arrow_array.type):
                param = kwargs[batch.component_descriptor().component]  # type: ignore[index]
                shape = np.shape(param)  # type: ignore[arg-type]
                elem_flat_len = int(np.prod(shape[1:])) if len(shape) > 1 else 1  # type: ignore[redundant-expr,misc]

                if pa.types.is_fixed_size_list(arrow_array.type) and arrow_array.type.list_size == elem_flat_len:
                    # If the product of the last dimensions of the shape are equal to the size of the fixed size list array,
                    # we have `num_rows` single element batches (each element is a fixed sized list).
                    # (This should have been already validated by conversion to the arrow_array)
                    batch_length = 1
                else:
                    batch_length = shape[1] if len(shape) > 1 else 1  # type: ignore[redundant-expr,misc]

                num_rows = shape[0] if len(shape) >= 1 else 1  # type: ignore[redundant-expr,misc]
                sizes = batch_length * np.ones(num_rows)
            else:
                # For non-primitive types, default to partitioning each element separately.
                sizes = np.ones(len(arrow_array))

            columns.append(batch.partition(sizes))

        return ComponentColumnList(columns)

    codec: components.VideoCodecBatch | None = field(
        metadata={"component": True},
        default=None,
        converter=components.VideoCodecBatch._converter,  # type: ignore[misc]
    )
    # The codec used to encode the video chunks.
    #
    # This property is expected to be constant over time and is ideally logged statically once per stream.
    #
    # (Docstring intentionally commented out to hide this field from the docs)

    sample: components.VideoSampleBatch | None = field(
        metadata={"component": True},
        default=None,
        converter=components.VideoSampleBatch._converter,  # type: ignore[misc]
    )
    # Video sample data (also known as "video chunk").
    #
    # The current timestamp is used as presentation timestamp (PTS) for all data in this sample.
    # There is currently no way to log differing decoding timestamps, meaning
    # that there is no support for B-frames.
    # See <https://github.com/rerun-io/rerun/issues/10090> for more details.
    #
    # Unlike any other data in Rerun, video samples are not allowed to be logged out of order,
    # as this may break live video playback.
    # I.e. any appended sample should have a timestamp greater than all previously logged samples.
    #
    # The samples are expected to be encoded using the `codec` field.
    # Each video sample must contain enough data for exactly one video frame
    # (this restriction may be relaxed in the future for some codecs).
    #
    # Unless your stream consists entirely of key-frames (in which case you should consider [`archetypes.EncodedImage`][rerun.archetypes.EncodedImage])
    # never log this component as static data as this means that you loose all information of
    # previous samples which may be required to decode an image.
    #
    # See [`components.VideoCodec`][rerun.components.VideoCodec] for codec specific requirements.
    #
    # (Docstring intentionally commented out to hide this field from the docs)

    draw_order: components.DrawOrderBatch | None = field(
        metadata={"component": True},
        default=None,
        converter=components.DrawOrderBatch._converter,  # type: ignore[misc]
    )
    # An optional floating point value that specifies the 2D drawing order.
    #
    # Objects with higher values are drawn on top of those with lower values.
    # Defaults to `-15.0`.
    #
    # (Docstring intentionally commented out to hide this field from the docs)

    __str__ = Archetype.__str__
    __repr__ = Archetype.__repr__  # type: ignore[assignment]
