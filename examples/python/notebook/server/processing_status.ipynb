{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8554b047-8616-4dd9-9494-1d2b22d5e9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450fd1f4-65e6-463c-a5ae-18c5b31aeeb7",
   "metadata": {},
   "source": [
    "# Data processing status example\n",
    "\n",
    "This example assumes you have started the OSS server using the dataset example located in the test\n",
    "asset directory. From the rerun repository you can start this using the following command.\n",
    "\n",
    "```shell\n",
    "rerun server --dataset ./tests/assets/rrd/dataset\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017f2c20-62c4-426c-842d-2c41d3da49c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datafusion import col, functions as F\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from rerun.catalog import CatalogClient, DatasetEntry\n",
    "from typing import TYPE_CHECKING\n",
    "import pyarrow as pa\n",
    "import tempfile\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from collections.abc import Generator\n",
    "\n",
    "CATALOG_URL = \"rerun+http://localhost:51234\"\n",
    "DATASET_NAME = \"dataset\"\n",
    "\n",
    "STATUS_TABLE_NAME = \"status\"\n",
    "RESULTS_TABLE_NAME = \"results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae278a02-fe2d-4efe-b6c5-5214f2c5edf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_status_table(client: CatalogClient, directory: Path) -> DataFrame:\n",
    "    if STATUS_TABLE_NAME in client.table_names():\n",
    "        return client.get_table(name=STATUS_TABLE_NAME)\n",
    "    \n",
    "    schema = pa.schema([\n",
    "        (\"rerun_partition_id\", pa.utf8()),\n",
    "        (\"is_complete\", pa.bool_()),\n",
    "        (\"update_time\", pa.timestamp(unit=\"ms\")),\n",
    "    ])\n",
    "    url = f\"file://{directory}/{STATUS_TABLE_NAME}\"\n",
    "\n",
    "    client.create_table(STATUS_TABLE_NAME, schema, url)\n",
    "    return client.get_table(name=STATUS_TABLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d529be-018e-434a-9c74-92bd94256298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_table(client: CatalogClient, directory: Path) -> DataFrame:\n",
    "    if RESULTS_TABLE_NAME in client.table_names():\n",
    "        return client.get_table(name=RESULTS_TABLE_NAME)\n",
    "    \n",
    "    schema = pa.schema([\n",
    "        (\"rerun_partition_id\", pa.utf8()),\n",
    "        (\"first_log_time\", pa.timestamp(unit=\"ns\")),\n",
    "        (\"last_log_time\", pa.timestamp(unit=\"ns\")),\n",
    "        (\"first_position_obj1\", pa.list_(pa.float32(), 3)),\n",
    "        (\"first_position_obj2\", pa.list_(pa.float32(), 3)),\n",
    "        (\"first_position_obj3\", pa.list_(pa.float32(), 3)),\n",
    "    ])\n",
    "    url = f\"file://{directory}/{RESULTS_TABLE_NAME}\"\n",
    "\n",
    "    client.create_table(RESULTS_TABLE_NAME, schema, url)\n",
    "    return client.get_table(name=RESULTS_TABLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bffdb0-c470-4470-8302-e3f16f3c60f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_missing_partitions(\n",
    "    partition_table: DataFrame,\n",
    "    status_table: DataFrame\n",
    ") -> List[str]:\n",
    "    status_table = status_table.filter(col(\"is_complete\") == True)\n",
    "    partitions = partition_table.join(status_table, on=\"rerun_partition_id\", how=\"anti\").collect()\n",
    "    return [r for rss in partitions for rs in rss for r in rs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbd4a67-ff8a-4df7-bd16-a24c68b36920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_partitions(client: ConnectionClient, dataset: DatasetEntry, partition_list: list[pa.ScalarValue]) -> None:\n",
    "    client.append_to_table(\n",
    "        STATUS_TABLE_NAME,\n",
    "        rerun_partition_id=partition_list,\n",
    "        is_complete=[False] * len(partition_list),\n",
    "        update_time = [datetime.now()] * len(partition_list)\n",
    "    )\n",
    "    partition_list = [str(p) for p in partition_list]\n",
    "\n",
    "    df = dataset.dataframe_query_view(index=\"time_1\", contents=\"/**\").filter_partition_id(*partition_list).df()\n",
    "\n",
    "    df = (\n",
    "        df\n",
    "        .aggregate(\n",
    "            \"rerun_partition_id\",\n",
    "            [\n",
    "                F.min(col(\"log_time\")).alias(\"first_log_time\"),\n",
    "                F.max(col(\"log_time\")).alias(\"last_log_time\"),\n",
    "                F.first_value(\n",
    "                    col(\"/obj1:Points3D:positions\")[0],\n",
    "                    filter=col(\"/obj1:Points3D:positions\").is_not_null(),\n",
    "                    order_by=col(\"time_1\")\n",
    "                ).alias(\"first_position_obj1\"),\n",
    "                F.first_value(\n",
    "                    col(\"/obj2:Points3D:positions\")[0],\n",
    "                    filter=col(\"/obj2:Points3D:positions\").is_not_null(),\n",
    "                    order_by=col(\"time_1\")\n",
    "                ).alias(\"first_position_obj2\"),\n",
    "                F.first_value(\n",
    "                    col(\"/obj3:Points3D:positions\")[0],\n",
    "                    filter=col(\"/obj3:Points3D:positions\").is_not_null(),\n",
    "                    order_by=col(\"time_1\")\n",
    "                ).alias(\"first_position_obj3\"),\n",
    "            ]  \n",
    "        )\n",
    "    )\n",
    "\n",
    "    df.write_table(RESULTS_TABLE_NAME)\n",
    "    \n",
    "    client.append_to_table(\n",
    "        STATUS_TABLE_NAME,\n",
    "        rerun_partition_id=partition_list,\n",
    "        is_complete=[True] * len(partition_list), # Add the `True` value to prevent this from processing again\n",
    "        update_time = [datetime.now()] * len(partition_list)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98997083-0a57-49b3-b010-4095549dc647",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    temp_path = Path(temp_dir)\n",
    "    \n",
    "    client = CatalogClient(CATALOG_URL)\n",
    "    dataset = client.get_dataset(name=DATASET_NAME)\n",
    "    \n",
    "    status_table = create_status_table(client, temp_path)\n",
    "    results_table = create_results_table(client, temp_path)\n",
    "\n",
    "    # TODO(tsaucer) replace with partition table query\n",
    "    partition_table = dataset.dataframe_query_view(index=\"time_1\", contents=\"/**\").df().select(\"rerun_partition_id\").distinct()\n",
    "\n",
    "    missing_partitions = None\n",
    "    while missing_partitions is None or len(missing_partitions) != 0:\n",
    "        missing_partitions = find_missing_partitions(partition_table, status_table)\n",
    "        print(f\"{len(missing_partitions)} of {partition_table.count()} partitions have not processed.\")\n",
    "\n",
    "        if len(missing_partitions) > 0:\n",
    "            process_partitions(client, dataset, missing_partitions[0:3])\n",
    "\n",
    "    display(results_table)\n",
    "\n",
    "    display(status_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4b9c6a-a774-4fff-a746-3f342ec56d84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
