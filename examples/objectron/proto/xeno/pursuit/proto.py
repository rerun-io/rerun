# Generated by the protocol buffer compiler.  DO NOT EDIT!
# sources: object.proto, annotation_data.proto
# plugin: python-betterproto
from dataclasses import dataclass
from typing import List

import betterproto

from .research.compvideo import arcapture


class ObjectType(betterproto.Enum):
    UNDEFINED_TYPE = 0
    BOUNDING_BOX = 1
    SKELETON = 2
    MESH = 3


class ObjectMethod(betterproto.Enum):
    UNKNOWN_METHOD = 0
    ANNOTATION = 1
    AUGMENTATION = 2


@dataclass
class KeyPoint(betterproto.Message):
    # The position of the keypoint in the local coordinate system of the rigid
    # object.
    x: float = betterproto.float_field(1)
    y: float = betterproto.float_field(2)
    z: float = betterproto.float_field(3)
    # Sphere around the keypoint, indiciating annotator's confidence of the
    # position in meters.
    confidence_radius: float = betterproto.float_field(4)
    # The name of the keypoint (e.g. legs, head, etc.). Does not have to be
    # unique.
    name: str = betterproto.string_field(5)
    # Indicates whether the keypoint is hidden or not.
    hidden: bool = betterproto.bool_field(6)


@dataclass
class Object(betterproto.Message):
    # Unique object id through a sequence. There might be multiple objects of the
    # same label in this sequence.
    id: int = betterproto.int32_field(1)
    # Describes what category an object is. E.g. object class, attribute,
    # instance or person identity. This provides additional context for the
    # object type.
    category: str = betterproto.string_field(2)
    type: "ObjectType" = betterproto.enum_field(3)
    # 3x3 row-major rotation matrix describing the orientation of the rigid
    # object's frame of reference in the world-coordinate system.
    rotation: List[float] = betterproto.float_field(4)
    # 3x1 vector describing the translation of the rigid object's frame of
    # reference in the world-coordinate system in meters.
    translation: List[float] = betterproto.float_field(5)
    # 3x1 vector describing the scale of the rigid object's frame of reference in
    # the world-coordinate system in meters.
    scale: List[float] = betterproto.float_field(6)
    # List of all the key points associated with this object in the object
    # coordinate system. The first keypoint is always the object's frame of
    # reference, e.g. the centroid of the box. E.g. bounding box with its center
    # as frame of reference, the 9 keypoints : {0., 0., 0.}, {-.5, -.5, -.5},
    # {-.5, -.5, +.5}, {-.5, +.5, -.5}, {-.5, +.5, +.5}, {+.5, -.5, -.5}, {+.5,
    # -.5, +.5}, {+.5, +.5, -.5}, {+.5, +.5, +.5} To get the bounding box in the
    # world-coordinate system, we first scale the box then transform the scaled
    # box. For example, bounding box in the world coordinate system is rotation *
    # scale * keypoints + translation
    keypoints: List["KeyPoint"] = betterproto.message_field(7)
    method: "ObjectMethod" = betterproto.enum_field(8)


@dataclass
class Edge(betterproto.Message):
    """The edge connecting two keypoints together"""

    # keypoint id of the edge's source
    source: int = betterproto.int32_field(1)
    # keypoint id of the edge's sink
    sink: int = betterproto.int32_field(2)


@dataclass
class Skeleton(betterproto.Message):
    """
    The skeleton template for different objects (e.g. humans, chairs, hands,
    etc) The annotation tool reads the skeleton template dictionary.
    """

    # The origin keypoint in the object coordinate system. (i.e. Point 0, 0, 0)
    reference_keypoint: int = betterproto.int32_field(1)
    # The skeleton's category (e.g. human, chair, hand.). Should be unique in the
    # dictionary.
    category: str = betterproto.string_field(2)
    # Initialization value for all the keypoints in the skeleton in the object's
    # local coordinate system. Pursuit will transform these points using object's
    # transformation to get the keypoint in the world-cooridnate.
    keypoints: List["KeyPoint"] = betterproto.message_field(3)
    # List of edges connecting keypoints
    edges: List["Edge"] = betterproto.message_field(4)


@dataclass
class Skeletons(betterproto.Message):
    """
    The list of all the modeled skeletons in our library. These models can be
    objects (chairs, desks, etc), humans (full pose, hands, faces, etc), or
    box. We can have multiple skeletons in the same file.
    """

    object: List["Skeleton"] = betterproto.message_field(1)


@dataclass
class NormalizedPoint2D(betterproto.Message):
    """Projection of a 3D point on an image, and its metric depth."""

    # x-y position of the 2d keypoint in the image coordinate system. u,v \in [0,
    # 1], where top left corner is (0, 0) and the bottom-right corner is (1, 1).
    x: float = betterproto.float_field(1)
    y: float = betterproto.float_field(2)
    # The depth of the point in the camera coordinate system (in meters).
    depth: float = betterproto.float_field(3)


@dataclass
class Point3D(betterproto.Message):
    """
    The 3D point in the camera coordinate system, the scales are in meters.
    """

    x: float = betterproto.float_field(1)
    y: float = betterproto.float_field(2)
    z: float = betterproto.float_field(3)


@dataclass
class AnnotatedKeyPoint(betterproto.Message):
    id: int = betterproto.int32_field(1)
    point_3d: "Point3D" = betterproto.message_field(2)
    point_2d: "NormalizedPoint2D" = betterproto.message_field(3)


@dataclass
class ObjectAnnotation(betterproto.Message):
    # Reference to the object identifier in ObjectInstance.
    object_id: int = betterproto.int32_field(1)
    # For each objects, list all the annotated keypoints here. E.g. for bounding-
    # boxes, we have 8 keypoints, hands = 21 keypoints, etc. These normalized
    # points are the projection of the Object's 3D keypoint on the current
    # frame's camera poses.
    keypoints: List["AnnotatedKeyPoint"] = betterproto.message_field(2)
    # Visibiity of this annotation in a frame.
    visibility: float = betterproto.float_field(3)


@dataclass
class FrameAnnotation(betterproto.Message):
    # Unique frame id, corresponds to images.
    frame_id: int = betterproto.int32_field(1)
    # List of the annotated objects in this frame. Depending on how many object
    # are observable in this frame, we might have non or as much as
    # sequence.objects_size() annotations.
    annotations: List["ObjectAnnotation"] = betterproto.message_field(2)
    # Information about the camera transformation (in the world coordinate) and
    # imaging characteristics for a captured video frame.
    camera: arcapture.ARCamera = betterproto.message_field(3)
    # The timestamp for the frame.
    timestamp: float = betterproto.double_field(4)
    # Plane center and normal in camera frame.
    plane_center: List[float] = betterproto.float_field(5)
    plane_normal: List[float] = betterproto.float_field(6)


@dataclass
class Sequence(betterproto.Message):
    """
    The sequence protocol contains the annotation data for the entire video
    clip.
    """

    # List of all the annotated 3D objects in this sequence in the world
    # Coordinate system. Given the camera poses of each frame (also in the world-
    # coordinate) these objects bounding boxes can be projected to each frame to
    # get the per-frame annotation (i.e. image_annotation below).
    objects: List["Object"] = betterproto.message_field(1)
    # List of annotated data per each frame in sequence + frame information.
    frame_annotations: List["FrameAnnotation"] = betterproto.message_field(2)
